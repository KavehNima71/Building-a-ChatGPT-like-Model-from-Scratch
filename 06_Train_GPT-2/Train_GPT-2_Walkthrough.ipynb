{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VrFCH9hpEyip",
        "3in1e9BksgIh",
        "d7Psbf21OXiW",
        "w_a3OXnSeV0z",
        "RwaY_YcgRayy",
        "RTql4Ftiunfr",
        "f8tPUUrtQ9Pj",
        "lAoYRsvKN_8l",
        "WTVewgG-m7nq",
        "ih6sV9ljndzW",
        "LCzTHf8iitEt",
        "o_5f69nwPtY2",
        "W0QNbC0YPCKZ",
        "ACjVH6bBpAEV",
        "Tc_zTOcmOXir",
        "LfdeZV28aamI",
        "4hafbAF356Xv",
        "xOVMvcCB7wjV"
      ],
      "authorship_tag": "ABX9TyNvLVJ4kqDKeOj1V6UdTeGg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/howsam/Building-a-ChatGPT-like-Model-from-Scratch/blob/main/Train_GPT-2_Walkthrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uXkcYhkIxS-"
      },
      "source": [
        "#  <font color='#FFE15D'><b>💎 Train GPT-2 on TinyStories Dataset </b></font><font color='#FF0B55'></font><font color='#FF0B55'><b>[Walkthrough]</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrFCH9hpEyip",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# 🔴 **Environment Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3in1e9BksgIh",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## 🟠 Change the font size of the output cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_nYkVog8SUR",
        "outputId": "db7b9f00-957c-4bcc-d7cd-c80a811b0001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salam Howsam!\n"
          ]
        }
      ],
      "source": [
        "print('Salam Howsam!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmMM0EfKsSiO"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "shell = get_ipython()\n",
        "\n",
        "def adjust_font_size():\n",
        "  display(HTML('''<style>\n",
        "    body {\n",
        "      font-size: 20px;\n",
        "    }\n",
        "  '''))\n",
        "\n",
        "if adjust_font_size not in shell.events.callbacks['pre_execute']:\n",
        "  shell.events.register('pre_execute', adjust_font_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10N1yUE88XRW",
        "outputId": "e10a3d17-df9b-4e30-b966-d3fde4496555"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salam Howsam!\n"
          ]
        }
      ],
      "source": [
        "print('Salam Howsam!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "d7Psbf21OXiW"
      },
      "source": [
        "## 🟠 `pip`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv21KFRNOXiX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_a3OXnSeV0z",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# 🔴 **Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhlVJEkJeTsV",
        "outputId": "5f44d9cc-bc8c-4fa2-9ad4-c8c508b0fa0c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import json\n",
        "import yaml\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from pprint import pprint\n",
        "from itertools import cycle\n",
        "from datetime import datetime\n",
        "from termcolor import colored\n",
        "from dataclasses import dataclass, asdict\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from torchmetrics import MeanMetric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tokenizers\n",
        "tokenizers.__version__"
      ],
      "metadata": {
        "id": "nga-ozVSy1YO",
        "outputId": "541ede6e-84f9-4aba-8166-59eba6f7a31e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.19.1'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwaY_YcgRayy",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# 🔴 **Utils**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pmcazW7OXia",
        "outputId": "5e839c34-c9dc-4bfc-f3d3-6b8776d251a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def prepare_data(tokens, seq_len):\n",
        "    # Trim tokens so that total length is divisible by seq_len\n",
        "    n_tokens = (tokens.shape[0] // seq_len) * seq_len\n",
        "    tokens = tokens[:n_tokens]\n",
        "    # Reshape to 2D tensor\n",
        "    return tokens.view(-1, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpKbTUEIRayz",
        "outputId": "80879f39-72fc-4f31-d642-7f42a03e1d12"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def num_trainable_params(model):\n",
        "  nums = sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n",
        "  return nums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6LDfZvmOLcI",
        "outputId": "8aa3e231-d5fb-48e6-a034-c5f603856573"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Benchmarking function\n",
        "def calculate_time(model, x, num_runs=10):\n",
        "    torch.cuda.synchronize()\n",
        "    start = time.time()\n",
        "    for _ in range(num_runs):\n",
        "        model(x)\n",
        "    torch.cuda.synchronize()\n",
        "    return (time.time() - start) / num_runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTql4Ftiunfr"
      },
      "source": [
        "# 🔴 **Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqqBMjGnz1IL",
        "outputId": "542e5b9b-8638-4b83-e39e-30c1c7b8a7b0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "class TinyStoriesDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, seq_len):\n",
        "        self.seq_len = seq_len\n",
        "        self.data = prepare_data(data, seq_len+1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        return sample.long()#[:-1], sample[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔴 **Model**"
      ],
      "metadata": {
        "id": "f8tPUUrtQ9Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🟠 Multi Head Attention"
      ],
      "metadata": {
        "id": "lAoYRsvKN_8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.n_embd = config.n_embd\n",
        "        self.n_head = config.n_head\n",
        "        self.head_size = self.n_embd // self.n_head\n",
        "\n",
        "        self.qkv_proj = nn.Linear(self.n_embd, 3*self.n_embd, bias=False)\n",
        "        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
        "        self.c_proj.residual = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        # QKV linear\n",
        "        q, k, v = self.qkv_proj(x).view(B, T, 3*self.n_head, self.head_size).transpose(1, 2).chunk(3, dim=-3)\n",
        "        # Scaled Dot Product Attention using pytorch\n",
        "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
        "        # Reshape and final projection\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        y = self.c_proj(y)\n",
        "        return y"
      ],
      "metadata": {
        "id": "gnxYy1oIQcY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0152eb-5ce5-46a9-fa52-a5106db9e967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🟠 Feed Forward (MLP)"
      ],
      "metadata": {
        "id": "WTVewgG-m7nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.n_embd = config.n_embd\n",
        "        self.f_expnd = config.f_expnd\n",
        "\n",
        "        self.up_proj = nn.Linear(self.n_embd, int(self.f_expnd*self.n_embd), bias=False)\n",
        "        self.down_proj = nn.Linear(int(self.f_expnd*self.n_embd), self.n_embd, bias=False)\n",
        "        self.down_proj.residual = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.down_proj(F.gelu(self.up_proj(x)))"
      ],
      "metadata": {
        "id": "BTcx4J5Lm66z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13778fb5-c2fc-4075-a572-78aad504a43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🟠 Decoder Block"
      ],
      "metadata": {
        "id": "ih6sV9ljndzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.n_embd = config.n_embd\n",
        "        # Multi Head Attention\n",
        "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
        "        self.mha = MultiHeadAttention(config)\n",
        "        # Feed Forward Neural Network\n",
        "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = FeedForward(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.mha(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "Gq1kw31av9DR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "707d6fc5-4911-484e-aa31-bc33fee06c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🟠 GPT"
      ],
      "metadata": {
        "id": "LCzTHf8iitEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.wte = nn.Embedding(config.vocab_size, config.n_embd) # Token embedding\n",
        "        self.wpe = nn.Embedding(config.max_seq_len, config.n_embd) # Position embedding\n",
        "        self.decoders = nn.ModuleList([DecoderBlock(config) for _ in range(config.n_layer)]) # Decoders\n",
        "        self.lnf = nn.LayerNorm(config.n_embd)\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False) # Classifier\n",
        "        self.lm_head.weight = self.wte.weight # Weight tying\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        std = 0.02\n",
        "        if isinstance(module, nn.Linear):\n",
        "            if hasattr(module, 'residual'):\n",
        "                std *= (2*self.config.n_layer)**-0.5\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=std)\n",
        "            if module.bias is not None:\n",
        "                nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=std)\n",
        "\n",
        "    def forward(self, idx):\n",
        "        B, T = idx.shape\n",
        "        # Token Embedding + Position Embedding\n",
        "        x = self.wte(idx) + self.wpe(torch.arange(T, device=idx.device))\n",
        "        # Decoders\n",
        "        for decoder in self.decoders:\n",
        "            x = decoder(x)\n",
        "        # Classifier\n",
        "        x = self.lnf(x)\n",
        "        logits = self.lm_head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "Lmrc034JwvSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bfd4c46-d3b1-499b-f043-4b283f30df7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_5f69nwPtY2"
      },
      "source": [
        "# 🔴 **Config**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class DatasetConfig:\n",
        "    train_path: str\n",
        "    valid_path: str\n",
        "    tokenizer_path: str\n",
        "    batch_size: int = 32\n",
        "    seq_len: int = 128\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    vocab_size: int = 50257\n",
        "    max_seq_len: int = 1024\n",
        "    n_layer: int = 12\n",
        "    n_head: int = 12\n",
        "    n_embd: int = 768\n",
        "    f_expnd: int = 4\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class OptimizerConfig:\n",
        "    max_lr: float = 3e-4\n",
        "    betas: tuple = (0.9, 0.95)\n",
        "    weight_decay: float = 0.1\n",
        "    fused: bool = True\n",
        "    warmup_steps: int = 256\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    seed: int = 42\n",
        "    device: str = 'cuda'\n",
        "    total_tokens: int = 100_000\n",
        "    log_interval_tokens: int = 50_000\n",
        "    log_dir: str = 'logs'\n",
        "    run_name: str = 'gpt2_tinystories'\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class GenerationConfig:\n",
        "    prompts: list[str]\n",
        "    T: float = 0.9\n",
        "    max_seq_len: int = 128\n",
        "    top_k: int = 10\n",
        "    n_rep: int = 3\n",
        "    seed: int = 42\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MasterConfig:\n",
        "    data: DatasetConfig\n",
        "    model: GPTConfig\n",
        "    optimizer: OptimizerConfig\n",
        "    train: TrainConfig\n",
        "    generation: GenerationConfig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "oIkx-mzbztIg",
        "outputId": "4be1542c-f0cf-408f-f13b-dceeaf3f97c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0QNbC0YPCKZ"
      },
      "source": [
        "# 🔴 **Functions ⚙️**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACjVH6bBpAEV"
      },
      "source": [
        "## 🟠 Logger"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logger class for saving and plotting training logs\n",
        "class Logger:\n",
        "    \"\"\"\n",
        "    Manages training history logging, saving to disk, and plotting learning curves.\n",
        "    \"\"\"\n",
        "    def __init__(self, log_dir='logs', run_name='default_run'):\n",
        "        # Make dir\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        self.log_dir = os.path.join(log_dir, f\"{run_name}_{timestamp}\")\n",
        "        os.makedirs(self.log_dir, exist_ok=False)\n",
        "        # Create history dictionay\n",
        "        self.history = {\n",
        "            'train_loss': [],\n",
        "            'valid_loss': [],\n",
        "            'best_loss_valid': float('inf'),\n",
        "            'seen_tokens': [],\n",
        "            'elapsed_time': []\n",
        "        }\n",
        "\n",
        "    def log(self, train_loss, valid_loss, seen_tokens, elapsed_time=0):\n",
        "        self.history['train_loss'].append(train_loss)\n",
        "        self.history['valid_loss'].append(valid_loss)\n",
        "        self.history['seen_tokens'].append(seen_tokens)\n",
        "        self.history['elapsed_time'].append(elapsed_time)\n",
        "\n",
        "    def save(self, model, optimizer):\n",
        "        # Save history\n",
        "        file_path = os.path.join(self.log_dir, 'loss_history.json')\n",
        "        with open(file_path, 'w') as f:\n",
        "            json.dump(self.history, f, indent=4)\n",
        "        # Save best model and optimizer\n",
        "        current_loss_valid = self.history['valid_loss'][-1]\n",
        "        if current_loss_valid < self.history['best_loss_valid']:\n",
        "            log = dict(model=model.state_dict(), optimizer=optimizer)\n",
        "            torch.save(log, f'{self.log_dir}/best_model.pt')\n",
        "            self.history['best_loss_valid'] = current_loss_valid\n",
        "            print(\"✅ Model Saved!\")\n",
        "        self.plot()\n",
        "\n",
        "    def plot(self):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(self.history['seen_tokens'], self.history['train_loss'], label='Train Loss')\n",
        "        plt.plot(self.history['seen_tokens'], self.history['valid_loss'], label='Valid Loss')\n",
        "        plt.xlabel('Seen Tokens')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(f'Learning Curve')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(self.log_dir, 'learning_curve.png'))\n",
        "        plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhLxBeKtreKx",
        "outputId": "d0a37ab4-60f2-48fa-8187-91df5c9a1c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc_zTOcmOXir"
      },
      "source": [
        "## 🟠 Train ➰"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer class to manage model training, evaluation and reporting\n",
        "class LLMTrainer:\n",
        "    \"\"\"\n",
        "    Trainer handles training loops, periodic evaluation, logging, and sample generation.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, optimizer, train_loader, valid_loader, tokenizer,\n",
        "                 config, loss_fn=F.cross_entropy):\n",
        "\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.valid_loader = valid_loader\n",
        "        self.tokenizer = tokenizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.config = config\n",
        "        self.device = config.train.device\n",
        "\n",
        "        self.seen_tokens = 0\n",
        "        self.token_eval_counter = 0\n",
        "        self.total_tokens = config.train.total_tokens\n",
        "        self.log_interval_tokens = config.train.log_interval_tokens\n",
        "\n",
        "        self.logger = Logger(log_dir=config.train.log_dir, run_name=config.train.run_name)\n",
        "        self._print_config_summary()\n",
        "\n",
        "        self.generation = config.generation\n",
        "\n",
        "        # Save config as a yaml file\n",
        "        with open(f'{self.logger.log_dir}/config.yaml', 'w') as f:\n",
        "            yaml.dump(asdict(config), f, sort_keys=False, indent=4)\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Main training loop that stops when total token count is reached.\n",
        "        \"\"\"\n",
        "        # Initial evaluation before any training\n",
        "        initial_loss = self.evaluate()\n",
        "        self.logger.log(initial_loss, initial_loss, 0)\n",
        "        print(f\"👶 [Initial] Train Loss (Untrained Model): {initial_loss:.4f}\\n\")\n",
        "\n",
        "        loss_train = MeanMetric()\n",
        "        self.model.train()\n",
        "        train_iter = cycle(self.train_loader)\n",
        "\n",
        "        step = 0\n",
        "        total_steps = self.config.train.total_tokens // (self.config.data.batch_size*self.config.data.seq_len) + 1\n",
        "        batches = 0\n",
        "        start_time = time.time()\n",
        "        total_time_elapsed = 0\n",
        "\n",
        "        with tqdm(total=self.total_tokens, desc=\"Training\", unit=\"t\") as pbar:\n",
        "            while self.seen_tokens < self.total_tokens:\n",
        "                # Get inputs\n",
        "                inputs = next(train_iter).to(self.device)\n",
        "\n",
        "                # Forward pass\n",
        "                logits = self.model(inputs[:, :-1])\n",
        "\n",
        "                # Calculate loss\n",
        "                loss = self.loss_fn(logits.view(-1, logits.shape[-1]), inputs[:, 1:].flatten())\n",
        "\n",
        "                # Backward pass\n",
        "                loss.backward()\n",
        "\n",
        "                # Clip gradients\n",
        "                nn.utils.clip_grad.clip_grad_norm_(self.model.parameters(), max_norm=1.)\n",
        "\n",
        "                # Determine and set the learning rate for this iteration\n",
        "                lr = get_lr(step, total_steps, self.config.optimizer)\n",
        "                for group in self.optimizer.param_groups:\n",
        "                    group['lr'] = lr\n",
        "\n",
        "                # Update model\n",
        "                self.optimizer.step()\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # Calc running loss\n",
        "                loss_train.update(loss.item(), inputs.shape[0])\n",
        "\n",
        "                num_tokens_this_batch = inputs[:, :-1].numel()\n",
        "                self.seen_tokens += num_tokens_this_batch\n",
        "                self.token_eval_counter += num_tokens_this_batch\n",
        "                step += 1\n",
        "                batches += 1\n",
        "                elapsed = time.time() - start_time\n",
        "                batches_per_sec = batches / elapsed\n",
        "\n",
        "                pbar.set_postfix({\n",
        "                    \"B/S\": f\"{batches_per_sec:.2f}\",\n",
        "                    \"Loss\": f\"{loss_train.compute().item():.4f}\",\n",
        "                    \"LR\": f\"{self.optimizer.param_groups[0]['lr']:.2e}\",\n",
        "                })\n",
        "                pbar.update(num_tokens_this_batch)\n",
        "\n",
        "                # Evaluate & Generate & Log\n",
        "                if (self.token_eval_counter >= self.log_interval_tokens) or (self.seen_tokens >= self.total_tokens):\n",
        "                    total_time_elapsed += elapsed\n",
        "\n",
        "                    # Evaluate\n",
        "                    loss_valid = self.evaluate()\n",
        "                    print(f\"\\nValid Loss: {loss_valid:.4f}\")\n",
        "\n",
        "                    # Log\n",
        "                    self.logger.log(loss_train.compute().item(), loss_valid, self.seen_tokens, total_time_elapsed)\n",
        "                    self.logger.save()\n",
        "\n",
        "                    # Generate\n",
        "                    if self.generation:\n",
        "                        self.generate()\n",
        "\n",
        "                    # Reset\n",
        "                    self.token_eval_counter = 0\n",
        "                    batches = 0\n",
        "                    start_time = time.time()\n",
        "\n",
        "        self.logger.plot()\n",
        "\n",
        "    def evaluate(self):\n",
        "        \"\"\"\n",
        "        Evaluate model on validation set.\n",
        "        \"\"\"\n",
        "        loss_valid = MeanMetric()\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs in self.valid_loader:\n",
        "                inputs = inputs.to(self.device)\n",
        "                logits = self.model(inputs[:, :-1])\n",
        "                loss = self.loss_fn(logits.view(-1, logits.shape[-1]), inputs[:, 1:].flatten())\n",
        "                loss_valid.update(loss.item(), inputs.shape[0])\n",
        "        return loss_valid.compute().item()\n",
        "\n",
        "    def generate(self):\n",
        "        \"\"\"\n",
        "        Generate and print text samples from the model.\n",
        "        \"\"\"\n",
        "        generated_texts = []\n",
        "        for prompt in self.generation.prompts:\n",
        "            gen_text = generate(\n",
        "                self.model, self.tokenizer, prompt,\n",
        "                n_rep=self.generation.n_rep,\n",
        "                max_seq_len=self.generation.max_seq_len,\n",
        "                T=self.generation.T, top_k=self.generation.top_k,\n",
        "                seed=self.generation.seed)\n",
        "            generated_texts.append(gen_text)\n",
        "        # TODO: Save\n",
        "        # Print\n",
        "        # print(150*'.')\n",
        "        # item = 0\n",
        "        # prompt0 = self.generation.prompts[item]\n",
        "        # for gen_text in generated_texts[item]:\n",
        "        #     print(colored(f\"\\n{prompt0}\", \"green\"), end='')\n",
        "        #     print(colored(f\"{gen_text[len(prompt0):]}\", \"cyan\"))\n",
        "        #     print(150*'.')\n",
        "        # print()\n",
        "        item = 0\n",
        "        prompt0 = self.generation.prompts[item]\n",
        "        gen_text0 = generated_texts[item][0]\n",
        "        print(colored(f\"\\n{prompt0}\", \"green\"), end='')\n",
        "        print(colored(f\"{gen_text0[len(prompt0):]}\", \"cyan\"))\n",
        "        print()\n",
        "\n",
        "    def _print_config_summary(self):\n",
        "        \"\"\"\n",
        "        Print a summary table of training configuration.\n",
        "        \"\"\"\n",
        "        table = PrettyTable()\n",
        "        table.title = \"Training Configuration Summary\"\n",
        "        table.field_names = [\"Component\", \"Details\"]\n",
        "        # Model\n",
        "        table.add_row([\"Model Type\", str(self.model.config).replace(\"Config\", \"\")])\n",
        "        # Optimizer\n",
        "        optimizer_name = self.optimizer.__class__.__name__\n",
        "        optimizer_params = ', '.join([f\"{k}={v}\" for k, v in self.optimizer.defaults.items() if k in [\"lr\", \"betas\", \"weight_decay\", \"fused\"]])\n",
        "        optimizer_display = f\"{optimizer_name}({optimizer_params})\"\n",
        "        table.add_row([\"Optimizer\", optimizer_display])\n",
        "        # Parameters\n",
        "        total_params = sum(p.numel() for p in self.model.parameters())\n",
        "        te_params = self.model.wte.weight.numel()\n",
        "        table.add_row([\"Total Parameters (Tr+TE)\", f\"{total_params:,} ({total_params-te_params:,}+{te_params:,})\"])\n",
        "\n",
        "        table.add_row([\"Loss Function\", self.loss_fn.__name__ if hasattr(self.loss_fn, '__name__') else str(self.loss_fn)])\n",
        "        table.add_row([\"Batch Shape\", f\"{self.train_loader.batch_size}x{self.train_loader.dataset[0].shape[-1]-1}\"])\n",
        "        table.add_row([\"Device\", self.device])\n",
        "        table.add_row([\"Max Tokens\", f\"{self.total_tokens:,}\"])\n",
        "        table.add_row([\"Log Interval Tokens\", f\"{self.log_interval_tokens:,}\"])\n",
        "        print(table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_6nuZ2JsE5d8",
        "outputId": "b62f653b-8013-4156-edce-df40b55925c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX-PL19qWp4r"
      },
      "source": [
        "## 🟠 Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT(GPTConfig( vocab_size=10_000, max_seq_len=1024, n_layer=8, n_head=16, n_embd=128, f_expnd=4))\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "szCcZIjCh_Ux",
        "outputId": "fd63b47c-3261-41a4-eec6-e41148971815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT(\n",
              "  (wte): Embedding(10000, 128)\n",
              "  (wpe): Embedding(1024, 128)\n",
              "  (decoders): ModuleList(\n",
              "    (0-7): 8 x DecoderBlock(\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (mha): MultiHeadAttention(\n",
              "        (qkv_proj): Linear(in_features=128, out_features=384, bias=False)\n",
              "        (c_proj): Linear(in_features=128, out_features=128, bias=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): FeedForward(\n",
              "        (up_proj): Linear(in_features=128, out_features=512, bias=False)\n",
              "        (down_proj): Linear(in_features=512, out_features=128, bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lnf): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): Linear(in_features=128, out_features=10000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.optim.AdamW(model.parameters(), lr=0.002, betas=(0.9, 0.95), weight_decay=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "DesGtPc-sDJa",
        "outputId": "99074ccb-e768-4478-8e78-c1fcefad1574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdamW (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.95)\n",
              "    capturable: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.002\n",
              "    maximize: False\n",
              "    weight_decay: 0.1\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.optim.AdamW?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "j_0fLHsjtOA1",
        "outputId": "3c977d20-ce08-4724-fa21-9e5d292aa024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n, p in model.named_parameters():\n",
        "    print(n, p.shape, p.ndim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "FbFM2-ThsTCi",
        "outputId": "c3e67309-593e-4ca4-db46-5ce8a4bf9ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wte.weight torch.Size([10000, 128]) 2\n",
            "wpe.weight torch.Size([1024, 128]) 2\n",
            "decoders.0.ln1.weight torch.Size([128]) 1\n",
            "decoders.0.ln1.bias torch.Size([128]) 1\n",
            "decoders.0.mha.qkv_proj.weight torch.Size([384, 128]) 2\n",
            "decoders.0.mha.c_proj.weight torch.Size([128, 128]) 2\n",
            "decoders.0.ln2.weight torch.Size([128]) 1\n",
            "decoders.0.ln2.bias torch.Size([128]) 1\n",
            "decoders.0.mlp.up_proj.weight torch.Size([512, 128]) 2\n",
            "decoders.0.mlp.down_proj.weight torch.Size([128, 512]) 2\n",
            "decoders.1.ln1.weight torch.Size([128]) 1\n",
            "decoders.1.ln1.bias torch.Size([128]) 1\n",
            "decoders.1.mha.qkv_proj.weight torch.Size([384, 128]) 2\n",
            "decoders.1.mha.c_proj.weight torch.Size([128, 128]) 2\n",
            "decoders.1.ln2.weight torch.Size([128]) 1\n",
            "decoders.1.ln2.bias torch.Size([128]) 1\n",
            "decoders.1.mlp.up_proj.weight torch.Size([512, 128]) 2\n",
            "decoders.1.mlp.down_proj.weight torch.Size([128, 512]) 2\n",
            "decoders.2.ln1.weight torch.Size([128]) 1\n",
            "decoders.2.ln1.bias torch.Size([128]) 1\n",
            "decoders.2.mha.qkv_proj.weight torch.Size([384, 128]) 2\n",
            "decoders.2.mha.c_proj.weight torch.Size([128, 128]) 2\n",
            "decoders.2.ln2.weight torch.Size([128]) 1\n",
            "decoders.2.ln2.bias torch.Size([128]) 1\n",
            "decoders.2.mlp.up_proj.weight torch.Size([512, 128]) 2\n",
            "decoders.2.mlp.down_proj.weight torch.Size([128, 512]) 2\n",
            "decoders.3.ln1.weight torch.Size([128]) 1\n",
            "decoders.3.ln1.bias torch.Size([128]) 1\n",
            "decoders.3.mha.qkv_proj.weight torch.Size([384, 128]) 2\n",
            "decoders.3.mha.c_proj.weight torch.Size([128, 128]) 2\n",
            "decoders.3.ln2.weight torch.Size([128]) 1\n",
            "decoders.3.ln2.bias torch.Size([128]) 1\n",
            "decoders.3.mlp.up_proj.weight torch.Size([512, 128]) 2\n",
            "decoders.3.mlp.down_proj.weight torch.Size([128, 512]) 2\n",
            "decoders.4.ln1.weight torch.Size([128]) 1\n",
            "decoders.4.ln1.bias torch.Size([128]) 1\n",
            "decoders.4.mha.qkv_proj.weight torch.Size([384, 128]) 2\n",
            "decoders.4.mha.c_proj.weight torch.Size([128, 128]) 2\n",
            "decoders.4.ln2.weight torch.Size([128]) 1\n",
            "decoders.4.ln2.bias torch.Size([128]) 1\n",
            "decoders.4.mlp.up_proj.weight torch.Size([512, 128]) 2\n",
            "decoders.4.mlp.down_proj.weight torch.Size([128, 512]) 2\n",
            "decoders.5.ln1.weight torch.Size([128]) 1\n",
            "decoders.5.ln1.bias torch.Size([128]) 1\n",
            "decoders.5.mha.qkv_proj.weight torch.Size([384, 128]) 2\n",
            "decoders.5.mha.c_proj.weight torch.Size([128, 128]) 2\n",
            "decoders.5.ln2.weight torch.Size([128]) 1\n",
            "decoders.5.ln2.bias torch.Size([128]) 1\n",
            "decoders.5.mlp.up_proj.weight torch.Size([512, 128]) 2\n",
            "decoders.5.mlp.down_proj.weight torch.Size([128, 512]) 2\n",
            "decoders.6.ln1.weight torch.Size([128]) 1\n",
            "decoders.6.ln1.bias torch.Size([128]) 1\n",
            "decoders.6.mha.qkv_proj.weight torch.Size([384, 128]) 2\n",
            "decoders.6.mha.c_proj.weight torch.Size([128, 128]) 2\n",
            "decoders.6.ln2.weight torch.Size([128]) 1\n",
            "decoders.6.ln2.bias torch.Size([128]) 1\n",
            "decoders.6.mlp.up_proj.weight torch.Size([512, 128]) 2\n",
            "decoders.6.mlp.down_proj.weight torch.Size([128, 512]) 2\n",
            "decoders.7.ln1.weight torch.Size([128]) 1\n",
            "decoders.7.ln1.bias torch.Size([128]) 1\n",
            "decoders.7.mha.qkv_proj.weight torch.Size([384, 128]) 2\n",
            "decoders.7.mha.c_proj.weight torch.Size([128, 128]) 2\n",
            "decoders.7.ln2.weight torch.Size([128]) 1\n",
            "decoders.7.ln2.bias torch.Size([128]) 1\n",
            "decoders.7.mlp.up_proj.weight torch.Size([512, 128]) 2\n",
            "decoders.7.mlp.down_proj.weight torch.Size([128, 512]) 2\n",
            "lnf.weight torch.Size([128]) 1\n",
            "lnf.bias torch.Size([128]) 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_dict = {n:p for n, p in model.named_parameters() if p.requires_grad}\n",
        "param_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "ybJcfpGMtZBy",
        "outputId": "2f1077f9-3904-4d5e-d058-9e099744db18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'wte.weight': Parameter containing:\n",
              " tensor([[ 0.0265, -0.0098, -0.0038,  ...,  0.0193, -0.0031, -0.0147],\n",
              "         [-0.0170,  0.0051, -0.0267,  ...,  0.0281, -0.0110,  0.0167],\n",
              "         [-0.0152, -0.0182,  0.0156,  ..., -0.0106,  0.0223,  0.0250],\n",
              "         ...,\n",
              "         [ 0.0272, -0.0195,  0.0101,  ..., -0.0163,  0.0339,  0.0301],\n",
              "         [-0.0249,  0.0193,  0.0242,  ..., -0.0122, -0.0057, -0.0114],\n",
              "         [-0.0156,  0.0088,  0.0176,  ..., -0.0215, -0.0082,  0.0138]],\n",
              "        requires_grad=True),\n",
              " 'wpe.weight': Parameter containing:\n",
              " tensor([[-0.0217,  0.0044,  0.0008,  ...,  0.0153, -0.0309, -0.0074],\n",
              "         [ 0.0074, -0.0203,  0.0262,  ...,  0.0035, -0.0169,  0.0313],\n",
              "         [ 0.0219, -0.0263,  0.0042,  ...,  0.0132, -0.0231,  0.0142],\n",
              "         ...,\n",
              "         [-0.0296, -0.0257,  0.0050,  ...,  0.0015, -0.0009, -0.0159],\n",
              "         [ 0.0901, -0.0720, -0.0092,  ..., -0.0191, -0.0032, -0.0376],\n",
              "         [ 0.0595, -0.0001, -0.0016,  ..., -0.0367,  0.0143,  0.0209]],\n",
              "        requires_grad=True),\n",
              " 'decoders.0.ln1.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.0.ln1.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.0.mha.qkv_proj.weight': Parameter containing:\n",
              " tensor([[-0.0148,  0.0335,  0.0125,  ...,  0.0246, -0.0217,  0.0289],\n",
              "         [ 0.0164,  0.0086,  0.0034,  ..., -0.0057, -0.0126, -0.0580],\n",
              "         [ 0.0086,  0.0079, -0.0141,  ..., -0.0071,  0.0031,  0.0150],\n",
              "         ...,\n",
              "         [-0.0003,  0.0256, -0.0100,  ...,  0.0171, -0.0073, -0.0278],\n",
              "         [ 0.0046, -0.0002, -0.0236,  ..., -0.0108,  0.0035, -0.0227],\n",
              "         [ 0.0028, -0.0219, -0.0323,  ..., -0.0081, -0.0154, -0.0244]],\n",
              "        requires_grad=True),\n",
              " 'decoders.0.mha.c_proj.weight': Parameter containing:\n",
              " tensor([[-2.0095e-03, -1.0472e-02, -6.1366e-04,  ...,  3.0842e-03,\n",
              "           1.9526e-03,  1.6192e-03],\n",
              "         [ 1.6652e-03, -1.2849e-03,  2.5683e-04,  ...,  3.8573e-03,\n",
              "          -5.3132e-03, -6.6420e-05],\n",
              "         [-3.7705e-03, -7.6727e-03,  7.6786e-04,  ..., -7.2248e-03,\n",
              "           9.8070e-03,  1.8008e-03],\n",
              "         ...,\n",
              "         [-1.2081e-04,  2.8230e-03, -6.6414e-03,  ..., -1.8972e-03,\n",
              "           2.1403e-03,  7.2442e-04],\n",
              "         [-9.2208e-03, -2.3761e-03,  9.9124e-04,  ..., -1.3220e-03,\n",
              "           7.3882e-03,  5.6816e-03],\n",
              "         [-1.1114e-03,  1.3238e-02,  1.7976e-03,  ..., -3.4650e-03,\n",
              "           4.5493e-03, -2.3258e-03]], requires_grad=True),\n",
              " 'decoders.0.ln2.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.0.ln2.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.0.mlp.up_proj.weight': Parameter containing:\n",
              " tensor([[-0.0083, -0.0003,  0.0094,  ...,  0.0260,  0.0123, -0.0271],\n",
              "         [-0.0437,  0.0305,  0.0117,  ...,  0.0003,  0.0201,  0.0126],\n",
              "         [-0.0248, -0.0322, -0.0016,  ...,  0.0154, -0.0262,  0.0120],\n",
              "         ...,\n",
              "         [-0.0005, -0.0052, -0.0122,  ...,  0.0195, -0.0060,  0.0023],\n",
              "         [ 0.0065,  0.0052, -0.0155,  ..., -0.0122,  0.0081,  0.0346],\n",
              "         [-0.0404,  0.0229,  0.0181,  ...,  0.0068,  0.0038,  0.0077]],\n",
              "        requires_grad=True),\n",
              " 'decoders.0.mlp.down_proj.weight': Parameter containing:\n",
              " tensor([[-6.5231e-04,  1.2062e-02,  1.4257e-03,  ..., -6.4150e-03,\n",
              "           5.0914e-03, -5.7886e-03],\n",
              "         [-5.2700e-03,  8.6520e-04, -2.4126e-03,  ...,  3.8043e-03,\n",
              "          -5.3181e-03, -3.7778e-03],\n",
              "         [-7.6905e-04, -6.0514e-03, -5.0967e-03,  ..., -6.8300e-04,\n",
              "           7.4965e-03,  2.3953e-03],\n",
              "         ...,\n",
              "         [ 4.8045e-05,  5.3224e-03, -5.0086e-03,  ...,  4.6938e-03,\n",
              "          -4.2113e-03,  7.5064e-03],\n",
              "         [-8.6573e-03,  6.3215e-03, -2.9925e-04,  ...,  9.8893e-03,\n",
              "           2.1650e-03, -5.5685e-03],\n",
              "         [-2.1455e-03,  1.3364e-03, -8.3161e-04,  ...,  7.7288e-03,\n",
              "           1.0211e-03, -2.9148e-03]], requires_grad=True),\n",
              " 'decoders.1.ln1.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.1.ln1.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.1.mha.qkv_proj.weight': Parameter containing:\n",
              " tensor([[ 0.0193,  0.0231, -0.0202,  ..., -0.0093,  0.0029,  0.0246],\n",
              "         [-0.0194,  0.0136,  0.0138,  ...,  0.0236, -0.0470,  0.0135],\n",
              "         [ 0.0227, -0.0259,  0.0124,  ..., -0.0439, -0.0107,  0.0236],\n",
              "         ...,\n",
              "         [-0.0070,  0.0075,  0.0143,  ...,  0.0073,  0.0203, -0.0170],\n",
              "         [ 0.0216,  0.0127,  0.0011,  ..., -0.0078,  0.0339, -0.0184],\n",
              "         [ 0.0143,  0.0241, -0.0121,  ...,  0.0265,  0.0036,  0.0079]],\n",
              "        requires_grad=True),\n",
              " 'decoders.1.mha.c_proj.weight': Parameter containing:\n",
              " tensor([[-7.3691e-03, -1.0075e-03, -1.7404e-03,  ...,  6.9125e-04,\n",
              "          -4.3252e-04,  2.8098e-03],\n",
              "         [-6.5866e-03,  7.2676e-04, -3.0312e-04,  ...,  1.5113e-03,\n",
              "           6.7247e-04, -3.5066e-03],\n",
              "         [ 1.2410e-03, -2.4252e-03, -2.2383e-03,  ...,  1.8277e-03,\n",
              "          -1.6201e-03,  6.2281e-03],\n",
              "         ...,\n",
              "         [-2.3409e-03, -1.3553e-03,  7.4195e-03,  ...,  3.8164e-03,\n",
              "          -8.6155e-03, -8.3095e-03],\n",
              "         [-7.1469e-03,  2.1586e-03, -9.6522e-03,  ..., -6.3007e-03,\n",
              "           9.9182e-04,  6.9139e-03],\n",
              "         [ 1.9431e-03,  2.9549e-04, -5.6905e-05,  ...,  4.7903e-03,\n",
              "           3.2282e-03,  1.5683e-03]], requires_grad=True),\n",
              " 'decoders.1.ln2.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.1.ln2.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.1.mlp.up_proj.weight': Parameter containing:\n",
              " tensor([[ 0.0087, -0.0245, -0.0123,  ..., -0.0128, -0.0250,  0.0011],\n",
              "         [-0.0091,  0.0026, -0.0345,  ...,  0.0114, -0.0005, -0.0108],\n",
              "         [ 0.0031, -0.0019, -0.0116,  ..., -0.0282, -0.0014, -0.0198],\n",
              "         ...,\n",
              "         [ 0.0020, -0.0030,  0.0344,  ...,  0.0032,  0.0002,  0.0138],\n",
              "         [ 0.0178, -0.0020, -0.0077,  ..., -0.0069,  0.0011,  0.0100],\n",
              "         [ 0.0140,  0.0122, -0.0204,  ..., -0.0417,  0.0322,  0.0177]],\n",
              "        requires_grad=True),\n",
              " 'decoders.1.mlp.down_proj.weight': Parameter containing:\n",
              " tensor([[-0.0112, -0.0048,  0.0003,  ..., -0.0092,  0.0008,  0.0099],\n",
              "         [-0.0044,  0.0026, -0.0084,  ...,  0.0059,  0.0094, -0.0059],\n",
              "         [-0.0039, -0.0015, -0.0025,  ..., -0.0020,  0.0046, -0.0015],\n",
              "         ...,\n",
              "         [-0.0083,  0.0026, -0.0134,  ...,  0.0062, -0.0030,  0.0046],\n",
              "         [ 0.0018,  0.0018,  0.0022,  ..., -0.0059,  0.0076, -0.0098],\n",
              "         [-0.0058,  0.0029, -0.0021,  ..., -0.0117,  0.0058, -0.0017]],\n",
              "        requires_grad=True),\n",
              " 'decoders.2.ln1.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.2.ln1.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.2.mha.qkv_proj.weight': Parameter containing:\n",
              " tensor([[ 0.0376,  0.0086,  0.0233,  ..., -0.0148,  0.0089,  0.0022],\n",
              "         [ 0.0126, -0.0122,  0.0187,  ...,  0.0014,  0.0222, -0.0369],\n",
              "         [-0.0055,  0.0121,  0.0248,  ..., -0.0214, -0.0258,  0.0082],\n",
              "         ...,\n",
              "         [ 0.0245,  0.0110,  0.0258,  ...,  0.0010,  0.0165, -0.0177],\n",
              "         [ 0.0272, -0.0092, -0.0062,  ...,  0.0578,  0.0513, -0.0178],\n",
              "         [ 0.0108, -0.0308,  0.0042,  ...,  0.0149,  0.0161, -0.0028]],\n",
              "        requires_grad=True),\n",
              " 'decoders.2.mha.c_proj.weight': Parameter containing:\n",
              " tensor([[ 0.0026, -0.0013,  0.0015,  ...,  0.0051, -0.0113, -0.0054],\n",
              "         [ 0.0051, -0.0045, -0.0069,  ..., -0.0059, -0.0022, -0.0032],\n",
              "         [-0.0018, -0.0065, -0.0054,  ..., -0.0039,  0.0081,  0.0007],\n",
              "         ...,\n",
              "         [-0.0042,  0.0039, -0.0076,  ..., -0.0084, -0.0022,  0.0091],\n",
              "         [-0.0064,  0.0051, -0.0011,  ..., -0.0038,  0.0041,  0.0076],\n",
              "         [-0.0009,  0.0015, -0.0025,  ...,  0.0025, -0.0026, -0.0098]],\n",
              "        requires_grad=True),\n",
              " 'decoders.2.ln2.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.2.ln2.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.2.mlp.up_proj.weight': Parameter containing:\n",
              " tensor([[ 0.0006,  0.0098, -0.0265,  ...,  0.0107,  0.0350, -0.0032],\n",
              "         [ 0.0506,  0.0328, -0.0279,  ..., -0.0027, -0.0289,  0.0061],\n",
              "         [-0.0363,  0.0070,  0.0276,  ...,  0.0087, -0.0269,  0.0051],\n",
              "         ...,\n",
              "         [ 0.0057,  0.0259,  0.0056,  ...,  0.0241,  0.0258, -0.0025],\n",
              "         [-0.0180,  0.0096,  0.0178,  ..., -0.0040, -0.0139,  0.0030],\n",
              "         [-0.0250, -0.0037,  0.0103,  ..., -0.0058,  0.0176, -0.0232]],\n",
              "        requires_grad=True),\n",
              " 'decoders.2.mlp.down_proj.weight': Parameter containing:\n",
              " tensor([[ 3.6121e-03,  1.0422e-03, -4.9497e-03,  ..., -9.6367e-03,\n",
              "          -8.8146e-03,  2.2299e-03],\n",
              "         [-3.0025e-03, -3.1660e-03,  1.6775e-03,  ...,  2.1566e-03,\n",
              "          -9.0196e-03, -1.6411e-03],\n",
              "         [ 3.2266e-03, -9.9014e-03,  1.5204e-03,  ...,  2.2333e-03,\n",
              "          -5.0104e-03,  2.8957e-03],\n",
              "         ...,\n",
              "         [-1.6674e-03,  1.4386e-05,  2.9937e-03,  ..., -3.5746e-03,\n",
              "           4.3050e-03, -5.5334e-03],\n",
              "         [-4.6264e-03,  3.4748e-04,  4.1304e-03,  ..., -6.7676e-03,\n",
              "           1.0810e-03, -2.4854e-03],\n",
              "         [ 3.4408e-03,  7.4727e-04, -3.9196e-03,  ..., -4.2277e-03,\n",
              "          -2.8707e-03, -2.5707e-03]], requires_grad=True),\n",
              " 'decoders.3.ln1.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.3.ln1.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.3.mha.qkv_proj.weight': Parameter containing:\n",
              " tensor([[-0.0106,  0.0249,  0.0337,  ...,  0.0011,  0.0350, -0.0082],\n",
              "         [-0.0134,  0.0092,  0.0308,  ...,  0.0120, -0.0190,  0.0124],\n",
              "         [ 0.0017,  0.0224, -0.0285,  ...,  0.0082, -0.0146,  0.0135],\n",
              "         ...,\n",
              "         [ 0.0325,  0.0118,  0.0239,  ..., -0.0488,  0.0065, -0.0345],\n",
              "         [-0.0106,  0.0048,  0.0084,  ...,  0.0254,  0.0311,  0.0094],\n",
              "         [-0.0217,  0.0196, -0.0022,  ..., -0.0158,  0.0111,  0.0004]],\n",
              "        requires_grad=True),\n",
              " 'decoders.3.mha.c_proj.weight': Parameter containing:\n",
              " tensor([[ 4.7739e-05,  3.3927e-03, -4.3504e-03,  ...,  2.6217e-03,\n",
              "          -6.0145e-03, -2.4517e-03],\n",
              "         [-3.5802e-03,  3.2781e-03,  2.5639e-03,  ..., -2.6622e-03,\n",
              "           1.0221e-03,  8.4341e-04],\n",
              "         [-1.6221e-03,  1.6797e-03, -1.1944e-02,  ..., -8.5630e-03,\n",
              "          -1.6154e-03, -2.2345e-03],\n",
              "         ...,\n",
              "         [-4.3057e-03, -1.6837e-04,  1.0245e-03,  ..., -8.0598e-03,\n",
              "          -1.7077e-03, -9.2788e-04],\n",
              "         [-5.6870e-03,  1.1128e-02,  5.5329e-04,  ..., -2.9968e-03,\n",
              "           1.3271e-03, -2.9100e-03],\n",
              "         [ 4.2343e-03, -2.8708e-03,  4.7545e-03,  ...,  1.8530e-03,\n",
              "          -7.7272e-03,  3.7720e-03]], requires_grad=True),\n",
              " 'decoders.3.ln2.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.3.ln2.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.3.mlp.up_proj.weight': Parameter containing:\n",
              " tensor([[-0.0420, -0.0122,  0.0053,  ..., -0.0142,  0.0230,  0.0108],\n",
              "         [-0.0158,  0.0152,  0.0271,  ..., -0.0532, -0.0202, -0.0201],\n",
              "         [-0.0039,  0.0243, -0.0096,  ..., -0.0132,  0.0155,  0.0239],\n",
              "         ...,\n",
              "         [-0.0139,  0.0112, -0.0097,  ..., -0.0038,  0.0230, -0.0460],\n",
              "         [-0.0898, -0.0180,  0.0186,  ..., -0.0108,  0.0212,  0.0105],\n",
              "         [-0.0040,  0.0036,  0.0081,  ..., -0.0394, -0.0052, -0.0190]],\n",
              "        requires_grad=True),\n",
              " 'decoders.3.mlp.down_proj.weight': Parameter containing:\n",
              " tensor([[-0.0069, -0.0062,  0.0048,  ...,  0.0039,  0.0073, -0.0067],\n",
              "         [-0.0085, -0.0010, -0.0075,  ...,  0.0009,  0.0017, -0.0058],\n",
              "         [-0.0081, -0.0046, -0.0007,  ..., -0.0056,  0.0032, -0.0061],\n",
              "         ...,\n",
              "         [ 0.0027,  0.0079, -0.0007,  ..., -0.0041,  0.0053,  0.0025],\n",
              "         [-0.0028, -0.0122, -0.0012,  ..., -0.0043, -0.0107,  0.0011],\n",
              "         [ 0.0085,  0.0013,  0.0002,  ...,  0.0011, -0.0022, -0.0014]],\n",
              "        requires_grad=True),\n",
              " 'decoders.4.ln1.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.4.ln1.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.4.mha.qkv_proj.weight': Parameter containing:\n",
              " tensor([[-0.0275, -0.0152,  0.0201,  ..., -0.0391,  0.0111, -0.0363],\n",
              "         [ 0.0146,  0.0284,  0.0123,  ..., -0.0069, -0.0001,  0.0142],\n",
              "         [ 0.0159, -0.0349, -0.0012,  ...,  0.0018, -0.0247, -0.0110],\n",
              "         ...,\n",
              "         [-0.0430,  0.0146, -0.0147,  ..., -0.0393, -0.0184, -0.0344],\n",
              "         [-0.0025,  0.0033, -0.0180,  ..., -0.0211, -0.0033,  0.0007],\n",
              "         [-0.0131, -0.0153, -0.0132,  ..., -0.0182,  0.0203, -0.0175]],\n",
              "        requires_grad=True),\n",
              " 'decoders.4.mha.c_proj.weight': Parameter containing:\n",
              " tensor([[-0.0037, -0.0011, -0.0081,  ..., -0.0056,  0.0022, -0.0013],\n",
              "         [ 0.0073,  0.0048, -0.0064,  ..., -0.0029,  0.0056, -0.0069],\n",
              "         [-0.0110, -0.0013,  0.0006,  ..., -0.0014,  0.0020,  0.0002],\n",
              "         ...,\n",
              "         [-0.0085, -0.0051, -0.0037,  ...,  0.0063, -0.0006,  0.0041],\n",
              "         [-0.0037, -0.0009,  0.0033,  ..., -0.0001,  0.0006,  0.0044],\n",
              "         [ 0.0048, -0.0011, -0.0007,  ..., -0.0071,  0.0029, -0.0008]],\n",
              "        requires_grad=True),\n",
              " 'decoders.4.ln2.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.4.ln2.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.4.mlp.up_proj.weight': Parameter containing:\n",
              " tensor([[ 0.0019, -0.0273, -0.0102,  ..., -0.0012,  0.0051,  0.0172],\n",
              "         [-0.0171, -0.0143,  0.0285,  ...,  0.0010,  0.0018,  0.0216],\n",
              "         [-0.0210, -0.0009, -0.0098,  ..., -0.0098, -0.0215, -0.0432],\n",
              "         ...,\n",
              "         [ 0.0237,  0.0245,  0.0202,  ...,  0.0023,  0.0280, -0.0233],\n",
              "         [ 0.0241, -0.0367, -0.0007,  ...,  0.0240, -0.0115, -0.0019],\n",
              "         [ 0.0105,  0.0120,  0.0061,  ..., -0.0050,  0.0078, -0.0173]],\n",
              "        requires_grad=True),\n",
              " 'decoders.4.mlp.down_proj.weight': Parameter containing:\n",
              " tensor([[ 3.8397e-03, -1.4554e-03,  5.8036e-03,  ...,  1.0393e-02,\n",
              "          -2.1511e-03,  3.9121e-03],\n",
              "         [ 6.0799e-03, -3.6492e-03,  9.9353e-03,  ..., -4.1375e-03,\n",
              "           3.0817e-03,  7.6211e-05],\n",
              "         [-2.1489e-03,  1.4850e-03,  1.0218e-03,  ...,  8.5889e-04,\n",
              "          -2.3041e-03, -3.0260e-03],\n",
              "         ...,\n",
              "         [-8.6265e-03,  1.8328e-03,  1.3619e-03,  ..., -3.3538e-03,\n",
              "           8.2357e-03, -1.6210e-03],\n",
              "         [-6.1419e-03,  9.0476e-03, -4.0204e-04,  ..., -1.0301e-03,\n",
              "          -2.5644e-04,  4.3149e-03],\n",
              "         [ 2.2024e-03, -2.5828e-03,  5.4542e-03,  ..., -1.5334e-03,\n",
              "          -2.0027e-03, -7.6550e-03]], requires_grad=True),\n",
              " 'decoders.5.ln1.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.5.ln1.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.5.mha.qkv_proj.weight': Parameter containing:\n",
              " tensor([[-0.0123, -0.0209,  0.0250,  ..., -0.0063, -0.0059, -0.0045],\n",
              "         [-0.0375, -0.0295,  0.0005,  ...,  0.0153, -0.0020, -0.0221],\n",
              "         [ 0.0052,  0.0162,  0.0030,  ...,  0.0397,  0.0235,  0.0337],\n",
              "         ...,\n",
              "         [ 0.0024,  0.0072, -0.0085,  ..., -0.0430, -0.0213, -0.0126],\n",
              "         [-0.0215,  0.0252,  0.0003,  ...,  0.0090, -0.0066,  0.0095],\n",
              "         [ 0.0278, -0.0106, -0.0476,  ...,  0.0117,  0.0275,  0.0114]],\n",
              "        requires_grad=True),\n",
              " 'decoders.5.mha.c_proj.weight': Parameter containing:\n",
              " tensor([[-5.7994e-03,  6.8848e-03,  3.0240e-03,  ...,  7.6047e-03,\n",
              "           8.3840e-03, -5.2785e-03],\n",
              "         [ 2.3877e-04, -5.1140e-03, -6.2983e-03,  ...,  2.9440e-03,\n",
              "           1.1335e-03,  3.6154e-03],\n",
              "         [-1.7804e-03, -9.2768e-04,  5.3499e-03,  ...,  5.6127e-03,\n",
              "          -1.9696e-03, -8.9510e-03],\n",
              "         ...,\n",
              "         [-2.0429e-03,  1.6094e-05, -8.1309e-03,  ..., -7.4633e-03,\n",
              "           9.8128e-03, -6.9631e-03],\n",
              "         [-7.4977e-03, -5.3231e-03, -2.8891e-03,  ..., -6.6711e-03,\n",
              "           2.1624e-04,  6.1723e-04],\n",
              "         [ 6.9575e-03, -2.1875e-03, -3.2122e-03,  ..., -2.9545e-03,\n",
              "           2.2231e-03,  4.2593e-03]], requires_grad=True),\n",
              " 'decoders.5.ln2.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.5.ln2.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.5.mlp.up_proj.weight': Parameter containing:\n",
              " tensor([[ 0.0043,  0.0455, -0.0259,  ...,  0.0155, -0.0234, -0.0070],\n",
              "         [ 0.0096, -0.0176,  0.0027,  ..., -0.0100, -0.0115, -0.0178],\n",
              "         [-0.0287, -0.0035,  0.0160,  ..., -0.0082,  0.0125, -0.0079],\n",
              "         ...,\n",
              "         [-0.0182, -0.0050,  0.0105,  ..., -0.0217,  0.0216,  0.0565],\n",
              "         [-0.0276,  0.0038,  0.0023,  ..., -0.0009, -0.0179,  0.0158],\n",
              "         [-0.0062, -0.0149,  0.0019,  ..., -0.0298, -0.0150,  0.0333]],\n",
              "        requires_grad=True),\n",
              " 'decoders.5.mlp.down_proj.weight': Parameter containing:\n",
              " tensor([[ 0.0078,  0.0067, -0.0024,  ...,  0.0051,  0.0036,  0.0007],\n",
              "         [ 0.0051,  0.0024,  0.0017,  ..., -0.0028,  0.0035,  0.0050],\n",
              "         [ 0.0009,  0.0074,  0.0046,  ..., -0.0003, -0.0048, -0.0032],\n",
              "         ...,\n",
              "         [ 0.0078,  0.0101, -0.0068,  ...,  0.0025,  0.0073, -0.0004],\n",
              "         [-0.0119,  0.0005,  0.0008,  ...,  0.0027,  0.0004, -0.0004],\n",
              "         [-0.0026, -0.0001, -0.0065,  ...,  0.0019, -0.0007, -0.0033]],\n",
              "        requires_grad=True),\n",
              " 'decoders.6.ln1.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.6.ln1.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.6.mha.qkv_proj.weight': Parameter containing:\n",
              " tensor([[-0.0179, -0.0284,  0.0503,  ...,  0.0026, -0.0051, -0.0440],\n",
              "         [-0.0093,  0.0162, -0.0315,  ...,  0.0026,  0.0240,  0.0330],\n",
              "         [ 0.0043,  0.0055,  0.0143,  ..., -0.0016, -0.0036, -0.0170],\n",
              "         ...,\n",
              "         [-0.0101,  0.0270, -0.0288,  ..., -0.0089,  0.0018,  0.0046],\n",
              "         [-0.0118,  0.0094,  0.0037,  ...,  0.0124,  0.0138,  0.0157],\n",
              "         [ 0.0229, -0.0263, -0.0280,  ..., -0.0010, -0.0150, -0.0039]],\n",
              "        requires_grad=True),\n",
              " 'decoders.6.mha.c_proj.weight': Parameter containing:\n",
              " tensor([[-0.0043,  0.0031, -0.0065,  ...,  0.0033, -0.0002,  0.0005],\n",
              "         [-0.0089, -0.0014, -0.0043,  ..., -0.0009,  0.0041,  0.0066],\n",
              "         [ 0.0008,  0.0005, -0.0045,  ..., -0.0031,  0.0056, -0.0041],\n",
              "         ...,\n",
              "         [ 0.0051,  0.0084,  0.0099,  ..., -0.0017,  0.0061, -0.0008],\n",
              "         [-0.0046,  0.0061,  0.0062,  ...,  0.0002, -0.0015,  0.0022],\n",
              "         [-0.0083,  0.0010, -0.0063,  ...,  0.0070,  0.0024, -0.0025]],\n",
              "        requires_grad=True),\n",
              " 'decoders.6.ln2.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.6.ln2.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.6.mlp.up_proj.weight': Parameter containing:\n",
              " tensor([[-0.0085, -0.0289, -0.0062,  ..., -0.0072, -0.0215,  0.0175],\n",
              "         [-0.0101, -0.0439, -0.0103,  ..., -0.0323,  0.0208,  0.0143],\n",
              "         [-0.0063,  0.0008,  0.0194,  ...,  0.0124, -0.0175,  0.0248],\n",
              "         ...,\n",
              "         [ 0.0050,  0.0024,  0.0107,  ...,  0.0454,  0.0038, -0.0052],\n",
              "         [ 0.0038,  0.0061, -0.0151,  ...,  0.0023,  0.0259, -0.0376],\n",
              "         [ 0.0088,  0.0019,  0.0054,  ...,  0.0082,  0.0006, -0.0375]],\n",
              "        requires_grad=True),\n",
              " 'decoders.6.mlp.down_proj.weight': Parameter containing:\n",
              " tensor([[ 3.1404e-03, -1.1462e-03, -3.4116e-03,  ..., -1.6772e-04,\n",
              "           6.3334e-03,  6.2177e-03],\n",
              "         [-1.1743e-03,  6.4347e-03,  2.7471e-03,  ..., -2.7942e-04,\n",
              "          -1.7386e-03, -1.7641e-03],\n",
              "         [-1.2606e-03,  2.9389e-03, -6.4059e-03,  ...,  5.1932e-03,\n",
              "          -1.8488e-04, -3.6836e-03],\n",
              "         ...,\n",
              "         [-4.6574e-03,  1.1925e-02, -9.6467e-03,  ...,  1.4062e-02,\n",
              "           7.3527e-03, -7.3796e-03],\n",
              "         [-1.1957e-02,  5.7150e-03,  4.5407e-03,  ..., -2.4921e-03,\n",
              "           4.4283e-03,  4.9299e-04],\n",
              "         [-1.1736e-03, -3.3389e-03, -1.2281e-03,  ...,  2.8990e-05,\n",
              "          -1.1757e-03, -2.4869e-03]], requires_grad=True),\n",
              " 'decoders.7.ln1.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.7.ln1.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.7.mha.qkv_proj.weight': Parameter containing:\n",
              " tensor([[-0.0545, -0.0082,  0.0067,  ...,  0.0311, -0.0548, -0.0150],\n",
              "         [ 0.0154,  0.0025, -0.0400,  ..., -0.0189, -0.0065,  0.0332],\n",
              "         [-0.0082,  0.0164, -0.0332,  ..., -0.0001, -0.0072, -0.0441],\n",
              "         ...,\n",
              "         [-0.0091,  0.0104, -0.0273,  ..., -0.0135,  0.0051,  0.0386],\n",
              "         [-0.0045,  0.0085,  0.0045,  ..., -0.0198,  0.0005,  0.0028],\n",
              "         [ 0.0071, -0.0025, -0.0091,  ...,  0.0229, -0.0279,  0.0375]],\n",
              "        requires_grad=True),\n",
              " 'decoders.7.mha.c_proj.weight': Parameter containing:\n",
              " tensor([[ 0.0036,  0.0066, -0.0027,  ...,  0.0016, -0.0056, -0.0024],\n",
              "         [-0.0043, -0.0062, -0.0014,  ..., -0.0030, -0.0040, -0.0045],\n",
              "         [-0.0046, -0.0053,  0.0138,  ..., -0.0024,  0.0036,  0.0049],\n",
              "         ...,\n",
              "         [-0.0034, -0.0050,  0.0035,  ...,  0.0007,  0.0027, -0.0037],\n",
              "         [-0.0048, -0.0012,  0.0010,  ..., -0.0062,  0.0035, -0.0017],\n",
              "         [ 0.0016,  0.0004, -0.0003,  ...,  0.0061, -0.0070, -0.0015]],\n",
              "        requires_grad=True),\n",
              " 'decoders.7.ln2.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'decoders.7.ln2.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              " 'decoders.7.mlp.up_proj.weight': Parameter containing:\n",
              " tensor([[-0.0012, -0.0290, -0.0118,  ...,  0.0145, -0.0008, -0.0021],\n",
              "         [-0.0228, -0.0154, -0.0103,  ..., -0.0208, -0.0253, -0.0029],\n",
              "         [ 0.0362,  0.0097, -0.0087,  ..., -0.0112,  0.0182,  0.0042],\n",
              "         ...,\n",
              "         [-0.0015,  0.0058,  0.0340,  ..., -0.0047,  0.0036, -0.0015],\n",
              "         [ 0.0171, -0.0174,  0.0300,  ..., -0.0172,  0.0170,  0.0357],\n",
              "         [-0.0055, -0.0128, -0.0561,  ..., -0.0041, -0.0176, -0.0095]],\n",
              "        requires_grad=True),\n",
              " 'decoders.7.mlp.down_proj.weight': Parameter containing:\n",
              " tensor([[ 7.0002e-03, -1.0937e-02,  4.1659e-03,  ..., -1.9341e-03,\n",
              "           2.7374e-03, -9.1476e-03],\n",
              "         [-3.2951e-03, -6.4862e-04, -2.1867e-03,  ..., -1.1571e-02,\n",
              "          -2.7282e-03, -3.9197e-03],\n",
              "         [-4.2228e-03,  2.9794e-03, -9.8516e-04,  ...,  2.7240e-04,\n",
              "           1.5243e-02,  3.0016e-03],\n",
              "         ...,\n",
              "         [ 7.0392e-03, -5.2927e-03,  6.1115e-05,  ...,  6.5551e-03,\n",
              "           6.5522e-04, -5.5981e-03],\n",
              "         [ 5.0660e-03,  7.7652e-03,  1.6926e-03,  ...,  5.3596e-03,\n",
              "           1.2125e-03, -6.6561e-03],\n",
              "         [ 5.9005e-03, -2.8648e-03, -6.7473e-03,  ..., -4.5621e-03,\n",
              "          -1.4256e-03, -2.1647e-03]], requires_grad=True),\n",
              " 'lnf.weight': Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1.], requires_grad=True),\n",
              " 'lnf.bias': Parameter containing:\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decay_params = [p for _, p in param_dict.items() if p.ndim>=2]\n",
        "for p in decay_params:\n",
        "    print(p.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "collapsed": true,
        "id": "hrHWz6VSui1j",
        "outputId": "1ffe1daf-242b-4ba1-f4b1-577b81b94642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10000, 128])\n",
            "torch.Size([1024, 128])\n",
            "torch.Size([384, 128])\n",
            "torch.Size([128, 128])\n",
            "torch.Size([512, 128])\n",
            "torch.Size([128, 512])\n",
            "torch.Size([384, 128])\n",
            "torch.Size([128, 128])\n",
            "torch.Size([512, 128])\n",
            "torch.Size([128, 512])\n",
            "torch.Size([384, 128])\n",
            "torch.Size([128, 128])\n",
            "torch.Size([512, 128])\n",
            "torch.Size([128, 512])\n",
            "torch.Size([384, 128])\n",
            "torch.Size([128, 128])\n",
            "torch.Size([512, 128])\n",
            "torch.Size([128, 512])\n",
            "torch.Size([384, 128])\n",
            "torch.Size([128, 128])\n",
            "torch.Size([512, 128])\n",
            "torch.Size([128, 512])\n",
            "torch.Size([384, 128])\n",
            "torch.Size([128, 128])\n",
            "torch.Size([512, 128])\n",
            "torch.Size([128, 512])\n",
            "torch.Size([384, 128])\n",
            "torch.Size([128, 128])\n",
            "torch.Size([512, 128])\n",
            "torch.Size([128, 512])\n",
            "torch.Size([384, 128])\n",
            "torch.Size([128, 128])\n",
            "torch.Size([512, 128])\n",
            "torch.Size([128, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nodecay_params = [p for _, p in param_dict.items() if p.ndim<2]\n",
        "for p in nodecay_params:\n",
        "    print(p.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "collapsed": true,
        "id": "l34T5t-Svzym",
        "outputId": "bba48255-fb7c-4873-9e7f-a057e2347478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optim_groups = [\n",
        "    {\"params\": decay_params, \"weight_decay\": 0.1},\n",
        "    {\"params\": nodecay_params, \"weight_decay\": 0.0, \"lr\": 0.01, \"betas\": (0.8, 0.85)}\n",
        "]\n",
        "optim_groups"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "iuPBExQfv_AB",
        "outputId": "8da6a0c2-f065-4878-e3dc-4303a2c7600b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'params': [Parameter containing:\n",
              "   tensor([[ 0.0265, -0.0098, -0.0038,  ...,  0.0193, -0.0031, -0.0147],\n",
              "           [-0.0170,  0.0051, -0.0267,  ...,  0.0281, -0.0110,  0.0167],\n",
              "           [-0.0152, -0.0182,  0.0156,  ..., -0.0106,  0.0223,  0.0250],\n",
              "           ...,\n",
              "           [ 0.0272, -0.0195,  0.0101,  ..., -0.0163,  0.0339,  0.0301],\n",
              "           [-0.0249,  0.0193,  0.0242,  ..., -0.0122, -0.0057, -0.0114],\n",
              "           [-0.0156,  0.0088,  0.0176,  ..., -0.0215, -0.0082,  0.0138]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-0.0217,  0.0044,  0.0008,  ...,  0.0153, -0.0309, -0.0074],\n",
              "           [ 0.0074, -0.0203,  0.0262,  ...,  0.0035, -0.0169,  0.0313],\n",
              "           [ 0.0219, -0.0263,  0.0042,  ...,  0.0132, -0.0231,  0.0142],\n",
              "           ...,\n",
              "           [-0.0296, -0.0257,  0.0050,  ...,  0.0015, -0.0009, -0.0159],\n",
              "           [ 0.0901, -0.0720, -0.0092,  ..., -0.0191, -0.0032, -0.0376],\n",
              "           [ 0.0595, -0.0001, -0.0016,  ..., -0.0367,  0.0143,  0.0209]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-0.0148,  0.0335,  0.0125,  ...,  0.0246, -0.0217,  0.0289],\n",
              "           [ 0.0164,  0.0086,  0.0034,  ..., -0.0057, -0.0126, -0.0580],\n",
              "           [ 0.0086,  0.0079, -0.0141,  ..., -0.0071,  0.0031,  0.0150],\n",
              "           ...,\n",
              "           [-0.0003,  0.0256, -0.0100,  ...,  0.0171, -0.0073, -0.0278],\n",
              "           [ 0.0046, -0.0002, -0.0236,  ..., -0.0108,  0.0035, -0.0227],\n",
              "           [ 0.0028, -0.0219, -0.0323,  ..., -0.0081, -0.0154, -0.0244]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-2.0095e-03, -1.0472e-02, -6.1366e-04,  ...,  3.0842e-03,\n",
              "             1.9526e-03,  1.6192e-03],\n",
              "           [ 1.6652e-03, -1.2849e-03,  2.5683e-04,  ...,  3.8573e-03,\n",
              "            -5.3132e-03, -6.6420e-05],\n",
              "           [-3.7705e-03, -7.6727e-03,  7.6786e-04,  ..., -7.2248e-03,\n",
              "             9.8070e-03,  1.8008e-03],\n",
              "           ...,\n",
              "           [-1.2081e-04,  2.8230e-03, -6.6414e-03,  ..., -1.8972e-03,\n",
              "             2.1403e-03,  7.2442e-04],\n",
              "           [-9.2208e-03, -2.3761e-03,  9.9124e-04,  ..., -1.3220e-03,\n",
              "             7.3882e-03,  5.6816e-03],\n",
              "           [-1.1114e-03,  1.3238e-02,  1.7976e-03,  ..., -3.4650e-03,\n",
              "             4.5493e-03, -2.3258e-03]], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-0.0083, -0.0003,  0.0094,  ...,  0.0260,  0.0123, -0.0271],\n",
              "           [-0.0437,  0.0305,  0.0117,  ...,  0.0003,  0.0201,  0.0126],\n",
              "           [-0.0248, -0.0322, -0.0016,  ...,  0.0154, -0.0262,  0.0120],\n",
              "           ...,\n",
              "           [-0.0005, -0.0052, -0.0122,  ...,  0.0195, -0.0060,  0.0023],\n",
              "           [ 0.0065,  0.0052, -0.0155,  ..., -0.0122,  0.0081,  0.0346],\n",
              "           [-0.0404,  0.0229,  0.0181,  ...,  0.0068,  0.0038,  0.0077]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-6.5231e-04,  1.2062e-02,  1.4257e-03,  ..., -6.4150e-03,\n",
              "             5.0914e-03, -5.7886e-03],\n",
              "           [-5.2700e-03,  8.6520e-04, -2.4126e-03,  ...,  3.8043e-03,\n",
              "            -5.3181e-03, -3.7778e-03],\n",
              "           [-7.6905e-04, -6.0514e-03, -5.0967e-03,  ..., -6.8300e-04,\n",
              "             7.4965e-03,  2.3953e-03],\n",
              "           ...,\n",
              "           [ 4.8045e-05,  5.3224e-03, -5.0086e-03,  ...,  4.6938e-03,\n",
              "            -4.2113e-03,  7.5064e-03],\n",
              "           [-8.6573e-03,  6.3215e-03, -2.9925e-04,  ...,  9.8893e-03,\n",
              "             2.1650e-03, -5.5685e-03],\n",
              "           [-2.1455e-03,  1.3364e-03, -8.3161e-04,  ...,  7.7288e-03,\n",
              "             1.0211e-03, -2.9148e-03]], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[ 0.0193,  0.0231, -0.0202,  ..., -0.0093,  0.0029,  0.0246],\n",
              "           [-0.0194,  0.0136,  0.0138,  ...,  0.0236, -0.0470,  0.0135],\n",
              "           [ 0.0227, -0.0259,  0.0124,  ..., -0.0439, -0.0107,  0.0236],\n",
              "           ...,\n",
              "           [-0.0070,  0.0075,  0.0143,  ...,  0.0073,  0.0203, -0.0170],\n",
              "           [ 0.0216,  0.0127,  0.0011,  ..., -0.0078,  0.0339, -0.0184],\n",
              "           [ 0.0143,  0.0241, -0.0121,  ...,  0.0265,  0.0036,  0.0079]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-7.3691e-03, -1.0075e-03, -1.7404e-03,  ...,  6.9125e-04,\n",
              "            -4.3252e-04,  2.8098e-03],\n",
              "           [-6.5866e-03,  7.2676e-04, -3.0312e-04,  ...,  1.5113e-03,\n",
              "             6.7247e-04, -3.5066e-03],\n",
              "           [ 1.2410e-03, -2.4252e-03, -2.2383e-03,  ...,  1.8277e-03,\n",
              "            -1.6201e-03,  6.2281e-03],\n",
              "           ...,\n",
              "           [-2.3409e-03, -1.3553e-03,  7.4195e-03,  ...,  3.8164e-03,\n",
              "            -8.6155e-03, -8.3095e-03],\n",
              "           [-7.1469e-03,  2.1586e-03, -9.6522e-03,  ..., -6.3007e-03,\n",
              "             9.9182e-04,  6.9139e-03],\n",
              "           [ 1.9431e-03,  2.9549e-04, -5.6905e-05,  ...,  4.7903e-03,\n",
              "             3.2282e-03,  1.5683e-03]], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[ 0.0087, -0.0245, -0.0123,  ..., -0.0128, -0.0250,  0.0011],\n",
              "           [-0.0091,  0.0026, -0.0345,  ...,  0.0114, -0.0005, -0.0108],\n",
              "           [ 0.0031, -0.0019, -0.0116,  ..., -0.0282, -0.0014, -0.0198],\n",
              "           ...,\n",
              "           [ 0.0020, -0.0030,  0.0344,  ...,  0.0032,  0.0002,  0.0138],\n",
              "           [ 0.0178, -0.0020, -0.0077,  ..., -0.0069,  0.0011,  0.0100],\n",
              "           [ 0.0140,  0.0122, -0.0204,  ..., -0.0417,  0.0322,  0.0177]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-0.0112, -0.0048,  0.0003,  ..., -0.0092,  0.0008,  0.0099],\n",
              "           [-0.0044,  0.0026, -0.0084,  ...,  0.0059,  0.0094, -0.0059],\n",
              "           [-0.0039, -0.0015, -0.0025,  ..., -0.0020,  0.0046, -0.0015],\n",
              "           ...,\n",
              "           [-0.0083,  0.0026, -0.0134,  ...,  0.0062, -0.0030,  0.0046],\n",
              "           [ 0.0018,  0.0018,  0.0022,  ..., -0.0059,  0.0076, -0.0098],\n",
              "           [-0.0058,  0.0029, -0.0021,  ..., -0.0117,  0.0058, -0.0017]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[ 0.0376,  0.0086,  0.0233,  ..., -0.0148,  0.0089,  0.0022],\n",
              "           [ 0.0126, -0.0122,  0.0187,  ...,  0.0014,  0.0222, -0.0369],\n",
              "           [-0.0055,  0.0121,  0.0248,  ..., -0.0214, -0.0258,  0.0082],\n",
              "           ...,\n",
              "           [ 0.0245,  0.0110,  0.0258,  ...,  0.0010,  0.0165, -0.0177],\n",
              "           [ 0.0272, -0.0092, -0.0062,  ...,  0.0578,  0.0513, -0.0178],\n",
              "           [ 0.0108, -0.0308,  0.0042,  ...,  0.0149,  0.0161, -0.0028]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[ 0.0026, -0.0013,  0.0015,  ...,  0.0051, -0.0113, -0.0054],\n",
              "           [ 0.0051, -0.0045, -0.0069,  ..., -0.0059, -0.0022, -0.0032],\n",
              "           [-0.0018, -0.0065, -0.0054,  ..., -0.0039,  0.0081,  0.0007],\n",
              "           ...,\n",
              "           [-0.0042,  0.0039, -0.0076,  ..., -0.0084, -0.0022,  0.0091],\n",
              "           [-0.0064,  0.0051, -0.0011,  ..., -0.0038,  0.0041,  0.0076],\n",
              "           [-0.0009,  0.0015, -0.0025,  ...,  0.0025, -0.0026, -0.0098]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[ 0.0006,  0.0098, -0.0265,  ...,  0.0107,  0.0350, -0.0032],\n",
              "           [ 0.0506,  0.0328, -0.0279,  ..., -0.0027, -0.0289,  0.0061],\n",
              "           [-0.0363,  0.0070,  0.0276,  ...,  0.0087, -0.0269,  0.0051],\n",
              "           ...,\n",
              "           [ 0.0057,  0.0259,  0.0056,  ...,  0.0241,  0.0258, -0.0025],\n",
              "           [-0.0180,  0.0096,  0.0178,  ..., -0.0040, -0.0139,  0.0030],\n",
              "           [-0.0250, -0.0037,  0.0103,  ..., -0.0058,  0.0176, -0.0232]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[ 3.6121e-03,  1.0422e-03, -4.9497e-03,  ..., -9.6367e-03,\n",
              "            -8.8146e-03,  2.2299e-03],\n",
              "           [-3.0025e-03, -3.1660e-03,  1.6775e-03,  ...,  2.1566e-03,\n",
              "            -9.0196e-03, -1.6411e-03],\n",
              "           [ 3.2266e-03, -9.9014e-03,  1.5204e-03,  ...,  2.2333e-03,\n",
              "            -5.0104e-03,  2.8957e-03],\n",
              "           ...,\n",
              "           [-1.6674e-03,  1.4386e-05,  2.9937e-03,  ..., -3.5746e-03,\n",
              "             4.3050e-03, -5.5334e-03],\n",
              "           [-4.6264e-03,  3.4748e-04,  4.1304e-03,  ..., -6.7676e-03,\n",
              "             1.0810e-03, -2.4854e-03],\n",
              "           [ 3.4408e-03,  7.4727e-04, -3.9196e-03,  ..., -4.2277e-03,\n",
              "            -2.8707e-03, -2.5707e-03]], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-0.0106,  0.0249,  0.0337,  ...,  0.0011,  0.0350, -0.0082],\n",
              "           [-0.0134,  0.0092,  0.0308,  ...,  0.0120, -0.0190,  0.0124],\n",
              "           [ 0.0017,  0.0224, -0.0285,  ...,  0.0082, -0.0146,  0.0135],\n",
              "           ...,\n",
              "           [ 0.0325,  0.0118,  0.0239,  ..., -0.0488,  0.0065, -0.0345],\n",
              "           [-0.0106,  0.0048,  0.0084,  ...,  0.0254,  0.0311,  0.0094],\n",
              "           [-0.0217,  0.0196, -0.0022,  ..., -0.0158,  0.0111,  0.0004]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[ 4.7739e-05,  3.3927e-03, -4.3504e-03,  ...,  2.6217e-03,\n",
              "            -6.0145e-03, -2.4517e-03],\n",
              "           [-3.5802e-03,  3.2781e-03,  2.5639e-03,  ..., -2.6622e-03,\n",
              "             1.0221e-03,  8.4341e-04],\n",
              "           [-1.6221e-03,  1.6797e-03, -1.1944e-02,  ..., -8.5630e-03,\n",
              "            -1.6154e-03, -2.2345e-03],\n",
              "           ...,\n",
              "           [-4.3057e-03, -1.6837e-04,  1.0245e-03,  ..., -8.0598e-03,\n",
              "            -1.7077e-03, -9.2788e-04],\n",
              "           [-5.6870e-03,  1.1128e-02,  5.5329e-04,  ..., -2.9968e-03,\n",
              "             1.3271e-03, -2.9100e-03],\n",
              "           [ 4.2343e-03, -2.8708e-03,  4.7545e-03,  ...,  1.8530e-03,\n",
              "            -7.7272e-03,  3.7720e-03]], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-0.0420, -0.0122,  0.0053,  ..., -0.0142,  0.0230,  0.0108],\n",
              "           [-0.0158,  0.0152,  0.0271,  ..., -0.0532, -0.0202, -0.0201],\n",
              "           [-0.0039,  0.0243, -0.0096,  ..., -0.0132,  0.0155,  0.0239],\n",
              "           ...,\n",
              "           [-0.0139,  0.0112, -0.0097,  ..., -0.0038,  0.0230, -0.0460],\n",
              "           [-0.0898, -0.0180,  0.0186,  ..., -0.0108,  0.0212,  0.0105],\n",
              "           [-0.0040,  0.0036,  0.0081,  ..., -0.0394, -0.0052, -0.0190]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-0.0069, -0.0062,  0.0048,  ...,  0.0039,  0.0073, -0.0067],\n",
              "           [-0.0085, -0.0010, -0.0075,  ...,  0.0009,  0.0017, -0.0058],\n",
              "           [-0.0081, -0.0046, -0.0007,  ..., -0.0056,  0.0032, -0.0061],\n",
              "           ...,\n",
              "           [ 0.0027,  0.0079, -0.0007,  ..., -0.0041,  0.0053,  0.0025],\n",
              "           [-0.0028, -0.0122, -0.0012,  ..., -0.0043, -0.0107,  0.0011],\n",
              "           [ 0.0085,  0.0013,  0.0002,  ...,  0.0011, -0.0022, -0.0014]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-0.0275, -0.0152,  0.0201,  ..., -0.0391,  0.0111, -0.0363],\n",
              "           [ 0.0146,  0.0284,  0.0123,  ..., -0.0069, -0.0001,  0.0142],\n",
              "           [ 0.0159, -0.0349, -0.0012,  ...,  0.0018, -0.0247, -0.0110],\n",
              "           ...,\n",
              "           [-0.0430,  0.0146, -0.0147,  ..., -0.0393, -0.0184, -0.0344],\n",
              "           [-0.0025,  0.0033, -0.0180,  ..., -0.0211, -0.0033,  0.0007],\n",
              "           [-0.0131, -0.0153, -0.0132,  ..., -0.0182,  0.0203, -0.0175]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-0.0037, -0.0011, -0.0081,  ..., -0.0056,  0.0022, -0.0013],\n",
              "           [ 0.0073,  0.0048, -0.0064,  ..., -0.0029,  0.0056, -0.0069],\n",
              "           [-0.0110, -0.0013,  0.0006,  ..., -0.0014,  0.0020,  0.0002],\n",
              "           ...,\n",
              "           [-0.0085, -0.0051, -0.0037,  ...,  0.0063, -0.0006,  0.0041],\n",
              "           [-0.0037, -0.0009,  0.0033,  ..., -0.0001,  0.0006,  0.0044],\n",
              "           [ 0.0048, -0.0011, -0.0007,  ..., -0.0071,  0.0029, -0.0008]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[ 0.0019, -0.0273, -0.0102,  ..., -0.0012,  0.0051,  0.0172],\n",
              "           [-0.0171, -0.0143,  0.0285,  ...,  0.0010,  0.0018,  0.0216],\n",
              "           [-0.0210, -0.0009, -0.0098,  ..., -0.0098, -0.0215, -0.0432],\n",
              "           ...,\n",
              "           [ 0.0237,  0.0245,  0.0202,  ...,  0.0023,  0.0280, -0.0233],\n",
              "           [ 0.0241, -0.0367, -0.0007,  ...,  0.0240, -0.0115, -0.0019],\n",
              "           [ 0.0105,  0.0120,  0.0061,  ..., -0.0050,  0.0078, -0.0173]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[ 3.8397e-03, -1.4554e-03,  5.8036e-03,  ...,  1.0393e-02,\n",
              "            -2.1511e-03,  3.9121e-03],\n",
              "           [ 6.0799e-03, -3.6492e-03,  9.9353e-03,  ..., -4.1375e-03,\n",
              "             3.0817e-03,  7.6211e-05],\n",
              "           [-2.1489e-03,  1.4850e-03,  1.0218e-03,  ...,  8.5889e-04,\n",
              "            -2.3041e-03, -3.0260e-03],\n",
              "           ...,\n",
              "           [-8.6265e-03,  1.8328e-03,  1.3619e-03,  ..., -3.3538e-03,\n",
              "             8.2357e-03, -1.6210e-03],\n",
              "           [-6.1419e-03,  9.0476e-03, -4.0204e-04,  ..., -1.0301e-03,\n",
              "            -2.5644e-04,  4.3149e-03],\n",
              "           [ 2.2024e-03, -2.5828e-03,  5.4542e-03,  ..., -1.5334e-03,\n",
              "            -2.0027e-03, -7.6550e-03]], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-0.0123, -0.0209,  0.0250,  ..., -0.0063, -0.0059, -0.0045],\n",
              "           [-0.0375, -0.0295,  0.0005,  ...,  0.0153, -0.0020, -0.0221],\n",
              "           [ 0.0052,  0.0162,  0.0030,  ...,  0.0397,  0.0235,  0.0337],\n",
              "           ...,\n",
              "           [ 0.0024,  0.0072, -0.0085,  ..., -0.0430, -0.0213, -0.0126],\n",
              "           [-0.0215,  0.0252,  0.0003,  ...,  0.0090, -0.0066,  0.0095],\n",
              "           [ 0.0278, -0.0106, -0.0476,  ...,  0.0117,  0.0275,  0.0114]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-5.7994e-03,  6.8848e-03,  3.0240e-03,  ...,  7.6047e-03,\n",
              "             8.3840e-03, -5.2785e-03],\n",
              "           [ 2.3877e-04, -5.1140e-03, -6.2983e-03,  ...,  2.9440e-03,\n",
              "             1.1335e-03,  3.6154e-03],\n",
              "           [-1.7804e-03, -9.2768e-04,  5.3499e-03,  ...,  5.6127e-03,\n",
              "            -1.9696e-03, -8.9510e-03],\n",
              "           ...,\n",
              "           [-2.0429e-03,  1.6094e-05, -8.1309e-03,  ..., -7.4633e-03,\n",
              "             9.8128e-03, -6.9631e-03],\n",
              "           [-7.4977e-03, -5.3231e-03, -2.8891e-03,  ..., -6.6711e-03,\n",
              "             2.1624e-04,  6.1723e-04],\n",
              "           [ 6.9575e-03, -2.1875e-03, -3.2122e-03,  ..., -2.9545e-03,\n",
              "             2.2231e-03,  4.2593e-03]], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[ 0.0043,  0.0455, -0.0259,  ...,  0.0155, -0.0234, -0.0070],\n",
              "           [ 0.0096, -0.0176,  0.0027,  ..., -0.0100, -0.0115, -0.0178],\n",
              "           [-0.0287, -0.0035,  0.0160,  ..., -0.0082,  0.0125, -0.0079],\n",
              "           ...,\n",
              "           [-0.0182, -0.0050,  0.0105,  ..., -0.0217,  0.0216,  0.0565],\n",
              "           [-0.0276,  0.0038,  0.0023,  ..., -0.0009, -0.0179,  0.0158],\n",
              "           [-0.0062, -0.0149,  0.0019,  ..., -0.0298, -0.0150,  0.0333]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[ 0.0078,  0.0067, -0.0024,  ...,  0.0051,  0.0036,  0.0007],\n",
              "           [ 0.0051,  0.0024,  0.0017,  ..., -0.0028,  0.0035,  0.0050],\n",
              "           [ 0.0009,  0.0074,  0.0046,  ..., -0.0003, -0.0048, -0.0032],\n",
              "           ...,\n",
              "           [ 0.0078,  0.0101, -0.0068,  ...,  0.0025,  0.0073, -0.0004],\n",
              "           [-0.0119,  0.0005,  0.0008,  ...,  0.0027,  0.0004, -0.0004],\n",
              "           [-0.0026, -0.0001, -0.0065,  ...,  0.0019, -0.0007, -0.0033]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-0.0179, -0.0284,  0.0503,  ...,  0.0026, -0.0051, -0.0440],\n",
              "           [-0.0093,  0.0162, -0.0315,  ...,  0.0026,  0.0240,  0.0330],\n",
              "           [ 0.0043,  0.0055,  0.0143,  ..., -0.0016, -0.0036, -0.0170],\n",
              "           ...,\n",
              "           [-0.0101,  0.0270, -0.0288,  ..., -0.0089,  0.0018,  0.0046],\n",
              "           [-0.0118,  0.0094,  0.0037,  ...,  0.0124,  0.0138,  0.0157],\n",
              "           [ 0.0229, -0.0263, -0.0280,  ..., -0.0010, -0.0150, -0.0039]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-0.0043,  0.0031, -0.0065,  ...,  0.0033, -0.0002,  0.0005],\n",
              "           [-0.0089, -0.0014, -0.0043,  ..., -0.0009,  0.0041,  0.0066],\n",
              "           [ 0.0008,  0.0005, -0.0045,  ..., -0.0031,  0.0056, -0.0041],\n",
              "           ...,\n",
              "           [ 0.0051,  0.0084,  0.0099,  ..., -0.0017,  0.0061, -0.0008],\n",
              "           [-0.0046,  0.0061,  0.0062,  ...,  0.0002, -0.0015,  0.0022],\n",
              "           [-0.0083,  0.0010, -0.0063,  ...,  0.0070,  0.0024, -0.0025]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-0.0085, -0.0289, -0.0062,  ..., -0.0072, -0.0215,  0.0175],\n",
              "           [-0.0101, -0.0439, -0.0103,  ..., -0.0323,  0.0208,  0.0143],\n",
              "           [-0.0063,  0.0008,  0.0194,  ...,  0.0124, -0.0175,  0.0248],\n",
              "           ...,\n",
              "           [ 0.0050,  0.0024,  0.0107,  ...,  0.0454,  0.0038, -0.0052],\n",
              "           [ 0.0038,  0.0061, -0.0151,  ...,  0.0023,  0.0259, -0.0376],\n",
              "           [ 0.0088,  0.0019,  0.0054,  ...,  0.0082,  0.0006, -0.0375]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[ 3.1404e-03, -1.1462e-03, -3.4116e-03,  ..., -1.6772e-04,\n",
              "             6.3334e-03,  6.2177e-03],\n",
              "           [-1.1743e-03,  6.4347e-03,  2.7471e-03,  ..., -2.7942e-04,\n",
              "            -1.7386e-03, -1.7641e-03],\n",
              "           [-1.2606e-03,  2.9389e-03, -6.4059e-03,  ...,  5.1932e-03,\n",
              "            -1.8488e-04, -3.6836e-03],\n",
              "           ...,\n",
              "           [-4.6574e-03,  1.1925e-02, -9.6467e-03,  ...,  1.4062e-02,\n",
              "             7.3527e-03, -7.3796e-03],\n",
              "           [-1.1957e-02,  5.7150e-03,  4.5407e-03,  ..., -2.4921e-03,\n",
              "             4.4283e-03,  4.9299e-04],\n",
              "           [-1.1736e-03, -3.3389e-03, -1.2281e-03,  ...,  2.8990e-05,\n",
              "            -1.1757e-03, -2.4869e-03]], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-0.0545, -0.0082,  0.0067,  ...,  0.0311, -0.0548, -0.0150],\n",
              "           [ 0.0154,  0.0025, -0.0400,  ..., -0.0189, -0.0065,  0.0332],\n",
              "           [-0.0082,  0.0164, -0.0332,  ..., -0.0001, -0.0072, -0.0441],\n",
              "           ...,\n",
              "           [-0.0091,  0.0104, -0.0273,  ..., -0.0135,  0.0051,  0.0386],\n",
              "           [-0.0045,  0.0085,  0.0045,  ..., -0.0198,  0.0005,  0.0028],\n",
              "           [ 0.0071, -0.0025, -0.0091,  ...,  0.0229, -0.0279,  0.0375]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[ 0.0036,  0.0066, -0.0027,  ...,  0.0016, -0.0056, -0.0024],\n",
              "           [-0.0043, -0.0062, -0.0014,  ..., -0.0030, -0.0040, -0.0045],\n",
              "           [-0.0046, -0.0053,  0.0138,  ..., -0.0024,  0.0036,  0.0049],\n",
              "           ...,\n",
              "           [-0.0034, -0.0050,  0.0035,  ...,  0.0007,  0.0027, -0.0037],\n",
              "           [-0.0048, -0.0012,  0.0010,  ..., -0.0062,  0.0035, -0.0017],\n",
              "           [ 0.0016,  0.0004, -0.0003,  ...,  0.0061, -0.0070, -0.0015]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[-0.0012, -0.0290, -0.0118,  ...,  0.0145, -0.0008, -0.0021],\n",
              "           [-0.0228, -0.0154, -0.0103,  ..., -0.0208, -0.0253, -0.0029],\n",
              "           [ 0.0362,  0.0097, -0.0087,  ..., -0.0112,  0.0182,  0.0042],\n",
              "           ...,\n",
              "           [-0.0015,  0.0058,  0.0340,  ..., -0.0047,  0.0036, -0.0015],\n",
              "           [ 0.0171, -0.0174,  0.0300,  ..., -0.0172,  0.0170,  0.0357],\n",
              "           [-0.0055, -0.0128, -0.0561,  ..., -0.0041, -0.0176, -0.0095]],\n",
              "          requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([[ 7.0002e-03, -1.0937e-02,  4.1659e-03,  ..., -1.9341e-03,\n",
              "             2.7374e-03, -9.1476e-03],\n",
              "           [-3.2951e-03, -6.4862e-04, -2.1867e-03,  ..., -1.1571e-02,\n",
              "            -2.7282e-03, -3.9197e-03],\n",
              "           [-4.2228e-03,  2.9794e-03, -9.8516e-04,  ...,  2.7240e-04,\n",
              "             1.5243e-02,  3.0016e-03],\n",
              "           ...,\n",
              "           [ 7.0392e-03, -5.2927e-03,  6.1115e-05,  ...,  6.5551e-03,\n",
              "             6.5522e-04, -5.5981e-03],\n",
              "           [ 5.0660e-03,  7.7652e-03,  1.6926e-03,  ...,  5.3596e-03,\n",
              "             1.2125e-03, -6.6561e-03],\n",
              "           [ 5.9005e-03, -2.8648e-03, -6.7473e-03,  ..., -4.5621e-03,\n",
              "            -1.4256e-03, -2.1647e-03]], requires_grad=True)],\n",
              "  'weight_decay': 0.1},\n",
              " {'params': [Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "           1., 1.], requires_grad=True),\n",
              "   Parameter containing:\n",
              "   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "           0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)],\n",
              "  'weight_decay': 0.0,\n",
              "  'lr': 0.01,\n",
              "  'betas': (0.8, 0.85)}]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.optim.AdamW(optim_groups)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "collapsed": true,
        "id": "7z3hB-T7xAJk",
        "outputId": "d6bddf18-b4d5-4ad8-801a-f996bbb42a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdamW (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    weight_decay: 0.1\n",
              "\n",
              "Parameter Group 1\n",
              "    amsgrad: False\n",
              "    betas: (0.8, 0.85)\n",
              "    capturable: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.01\n",
              "    maximize: False\n",
              "    weight_decay: 0.0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def configure_optimizer(model, config: OptimizerConfig):\n",
        "    # start with all of the candidate parameters (that require grad)\n",
        "    param_dict = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
        "\n",
        "    # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
        "    # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
        "    decay_params = [p for _, p in param_dict.items() if p.ndim >= 2]\n",
        "    nodecay_params = [p for _, p in param_dict.items() if p.ndim < 2]\n",
        "\n",
        "    optim_groups = [\n",
        "        {\"params\": decay_params, \"weight_decay\": config.weight_decay},\n",
        "        {\"params\": nodecay_params, \"weight_decay\": 0.0}\n",
        "    ]\n",
        "\n",
        "    num_decay_params = sum(p.numel() for p in decay_params)\n",
        "    num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "    print(f\"🔹 num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
        "    print(f\"🔹 num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
        "\n",
        "    # Define Optimizer\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        optim_groups,\n",
        "        lr=config.max_lr,\n",
        "        betas=config.betas,\n",
        "        fused=config.fused)\n",
        "\n",
        "    return optimizer"
      ],
      "metadata": {
        "id": "9iTdKDg9xgK4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "db35ef87-5545-472c-a1b5-62ba6a615041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.optim.lr_scheduler."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 43
        },
        "id": "yrl1fqt21iZW",
        "outputId": "d6bd41c7-1053-4240-f85d-cce1040b84d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'torch.optim.lr_scheduler' from 'C:\\\\Users\\\\Howsam\\\\anaconda3\\\\envs\\\\torch-howsam-free\\\\Lib\\\\site-packages\\\\torch\\\\optim\\\\lr_scheduler.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(step, total_steps, config: OptimizerConfig):\n",
        "    assert step <= total_steps\n",
        "\n",
        "    # 1. Linear warmup for warmup_steps\n",
        "    if step < config.warmup_steps:\n",
        "        return config.max_lr * (step+1) / config.warmup_steps\n",
        "\n",
        "    # 2. Linear decay down to min learning rate\n",
        "    decay_ratio = (step - config.warmup_steps) / (total_steps - config.warmup_steps) # [0, 1]\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    return config.max_lr * (config.alpha + (1 - decay_ratio)) / (config.alpha + 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6Bz_rp-m3eMN",
        "outputId": "ad4226ea-4a79-495e-bcc7-51214c7361a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lr = get_lr(step, total_steps, cfg.optimizer)\n",
        "optimizer = configure_optimizer(model, OptimizerConfig(fused=False))\n",
        "print(optimizer)\n",
        "\n",
        "optimizer.param_groups[0].keys()\n",
        "optimizer.param_groups[0]['lr'] = 6e-10\n",
        "print(optimizer)\n",
        "\n",
        "for group in optimizer.param_groups:\n",
        "    print(group['lr'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "q5XfWzw1_soH",
        "outputId": "020b794c-02a5-460b-c812-2882aac918f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 num decayed parameter tensors: 34, with 2,983,936 parameters\n",
            "🔹 num non-decayed parameter tensors: 34, with 4,352 parameters\n",
            "AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.95)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: False\n",
            "    lr: 0.0003\n",
            "    maximize: False\n",
            "    weight_decay: 0.1\n",
            "\n",
            "Parameter Group 1\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.95)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: False\n",
            "    lr: 0.0003\n",
            "    maximize: False\n",
            "    weight_decay: 0.0\n",
            ")\n",
            "AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.95)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: False\n",
            "    lr: 6e-10\n",
            "    maximize: False\n",
            "    weight_decay: 0.1\n",
            "\n",
            "Parameter Group 1\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.95)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: False\n",
            "    lr: 0.0003\n",
            "    maximize: False\n",
            "    weight_decay: 0.0\n",
            ")\n",
            "6e-10\n",
            "0.0003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfdeZV28aamI"
      },
      "source": [
        "## 🟠 Generate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, tokenizer, prompt, n_rep=5, max_seq_len=128, T=0.9, top_k=10, device='cuda', seed=42):\n",
        "    # Get the token ID for <|endoftext|>\n",
        "    eot_token_id = tokenizer.encode(\"<|endoftext|>\").ids[0]\n",
        "\n",
        "    # Tokenize the prompt and convert it to a tensor on the specified device (e.g., GPU)\n",
        "    inputs = torch.tensor(tokenizer.encode(prompt).ids, dtype=torch.int, device=device)  # Shape: [T]\n",
        "\n",
        "    # Repeat the input prompt n_rep times to generate multiple sequences in parallel\n",
        "    inputs = inputs.unsqueeze(0).repeat(n_rep, 1)  # Shape: [B, T] where B = n_rep\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize a random number generator for sampling\n",
        "    sample_rng = torch.Generator(device=device)\n",
        "    sample_rng.manual_seed(seed)\n",
        "\n",
        "    # Track which sequences are still active\n",
        "    is_finished = torch.zeros(n_rep, dtype=torch.bool, device=device)\n",
        "\n",
        "    # Disable gradient calculation for faster inference\n",
        "    with torch.no_grad():\n",
        "        # Continue generating tokens until reaching the maximum sequence length\n",
        "        while inputs.shape[-1] < max_seq_len:\n",
        "            # Forward pass: get logits from the model\n",
        "            logits = model(inputs)  # Shape: [B, T, vocab_size]\n",
        "\n",
        "            # Apply temperature scaling and softmax to get probabilities for the next token\n",
        "            probs = torch.softmax(logits[:, -1, :] / T, dim=-1)  # Shape: [B, vocab_size]\n",
        "\n",
        "            # Select the top_k tokens with the highest probabilities\n",
        "            topk_probs, topk_indices = torch.topk(probs, k=top_k, dim=-1)  # Shape: [B, top_k]\n",
        "\n",
        "            # Sample one token from the top_k candidates based on their probabilities\n",
        "            sampled = torch.multinomial(topk_probs, 1, generator=sample_rng)  # Shape: [B, 1]\n",
        "\n",
        "            # Map the sampled indices back to the original token IDs\n",
        "            next_token = torch.gather(topk_indices, -1, sampled).squeeze(-1) # Shape: [B]\n",
        "\n",
        "            # For finished sequences, force pad with eot_token_id again to avoid changing inputs\n",
        "            next_token = torch.where(is_finished, torch.tensor(eot_token_id, device=device), next_token)\n",
        "\n",
        "            # Update finished mask\n",
        "            is_finished = is_finished | (next_token == eot_token_id)\n",
        "\n",
        "            # Append the sampled tokens to the input sequence\n",
        "            inputs = torch.cat((inputs, next_token.unsqueeze(-1)), dim=-1)  # Shape: [B, T+1]\n",
        "\n",
        "    # Decode the generated sequences back into text\n",
        "    generated_text = tokenizer.decode_batch(inputs.tolist())\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "q8AHJrxFTfs2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95cf2b8a-ae21-4f26-ee71-5d1ba9fa15b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_chat_style(prompt, generated_text, tokenizer, delay=0.03):\n",
        "    \"\"\"\n",
        "    Display generated text in a token-by-token ChatGPT-like style:\n",
        "    - prompt in green\n",
        "    - generated continuation in blue\n",
        "    \"\"\"\n",
        "    for i, full_text in enumerate(generated_text):\n",
        "        print(colored(f\"\\n[Sample {i+1}]\", \"yellow\"))\n",
        "        input_ids = tokenizer.encode(prompt).ids\n",
        "        full_ids = tokenizer.encode(full_text).ids\n",
        "\n",
        "        # Split into prompt tokens and continuation\n",
        "        prompt_tokens = full_ids[:len(input_ids)]\n",
        "        continuation_tokens = full_ids[len(input_ids):]\n",
        "\n",
        "        # Decode tokens separately\n",
        "        prompt_text = tokenizer.decode(prompt_tokens)\n",
        "        cont_tokens_text = [tokenizer.decode([tid]) for tid in continuation_tokens]\n",
        "\n",
        "        # Print prompt in green\n",
        "        sys.stdout.write(colored(prompt_text, 'green'))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "        # Print continuation token-by-token in blue\n",
        "        for token in cont_tokens_text:\n",
        "            sys.stdout.write(colored(token, 'cyan'))\n",
        "            sys.stdout.flush()\n",
        "            time.sleep(delay)\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItFI4ge5p_Tg",
        "outputId": "733daae4-1797-427a-ccb9-1597716682cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hafbAF356Xv"
      },
      "source": [
        "# 🔴 **Training Process 〽️**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "t5pYKteTi-1x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "69546281-651b-424c-8320-447aeca0762c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = MasterConfig(\n",
        "\n",
        "    data=DatasetConfig(\n",
        "        train_path='tokenized-train-samples_vocab-10k.pt',\n",
        "        valid_path='tokenized-valid-samples_vocab-10k.pt',\n",
        "        tokenizer_path='bpe-tokenizer_tinystories.json',\n",
        "        batch_size=48,\n",
        "        seq_len=512),\n",
        "\n",
        "    model=GPTConfig(\n",
        "        vocab_size=10_000,\n",
        "        max_seq_len=1024,\n",
        "        n_layer=8,\n",
        "        n_head=16,\n",
        "        n_embd=128,\n",
        "        f_expnd=4),\n",
        "\n",
        "    optimizer=OptimizerConfig(\n",
        "        max_lr=0.002,\n",
        "        betas=(0.9, 0.95),\n",
        "        weight_decay=0.1,\n",
        "        fused=True),\n",
        "\n",
        "    train=TrainConfig(\n",
        "        seed=42,\n",
        "        device='cuda',\n",
        "        total_tokens=460_000_000,\n",
        "        log_interval_tokens=20_000_000,\n",
        "        log_dir='logs',\n",
        "        run_name='gpt2_tinystories_lrs'),\n",
        "\n",
        "    generation=GenerationConfig(\n",
        "        prompts=['In last'],\n",
        "        T=0.9,\n",
        "        max_seq_len=512,\n",
        "        top_k=10,\n",
        "        n_rep=3,\n",
        "        seed=42)\n",
        "    )"
      ],
      "metadata": {
        "id": "8oeA0tN819pD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "87be6365-b7c5-4b1d-c832-f35214a8683e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a manual seed for reproducibility across runs\n",
        "torch.manual_seed(cfg.train.seed)\n",
        "\n",
        "# Load pre-tokenized training and validation token IDs from disk\n",
        "train_token_ids = torch.load(cfg.data.train_path)\n",
        "valid_token_ids = torch.load(cfg.data.valid_path)\n",
        "\n",
        "print(\"📊 Number of Tokens\")\n",
        "print(f\"🔹 Train: {len(train_token_ids):,} tokens\")\n",
        "print(f\"🔹 Valid: {len(valid_token_ids):,} tokens\")\n",
        "print()\n",
        "\n",
        "\n",
        "# Create dataset instances with fixed-length sequences\n",
        "train_set = TinyStoriesDataset(train_token_ids, cfg.data.seq_len)\n",
        "valid_set = TinyStoriesDataset(valid_token_ids, cfg.data.seq_len)\n",
        "\n",
        "\n",
        "# Create DataLoaders for batching and shuffling during training\n",
        "train_loader = DataLoader(train_set, batch_size=cfg.data.batch_size, shuffle=True, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=cfg.data.batch_size, shuffle=False, pin_memory=True)\n",
        "\n",
        "print(f\"📊 Number of Batches\")\n",
        "print(f\"🔹 Train: {len(train_loader):,} batches\")\n",
        "print(f\"🔹 Valid: {len(valid_loader):,} batches\")"
      ],
      "metadata": {
        "id": "9FQ8l4rrK2nW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "fa2424ee-cdd3-40e3-f605-9514b4922d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Number of Tokens\n",
            "🔹 Train: 464,965,814 tokens\n",
            "🔹 Valid: 4,673,588 tokens\n",
            "\n",
            "📊 Number of Batches\n",
            "🔹 Train: 18,883 batches\n",
            "🔹 Valid: 190 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer.from_file(cfg.data.tokenizer_path)"
      ],
      "metadata": {
        "id": "xpsiToA77Vex",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "22447307-4d72-429b-c8db-b508cf6ff97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT(cfg.model).to(cfg.train.device)\n",
        "\n",
        "print(model)\n",
        "print(f\"\\n📊 Number of Parameters: {num_trainable_params(model):.2f}M\")"
      ],
      "metadata": {
        "id": "i7zJv8yJEBLl",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "18860273-995c-4b55-8d65-594eabb153b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 20px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT(\n",
            "  (wte): Embedding(10000, 128)\n",
            "  (wpe): Embedding(1024, 128)\n",
            "  (decoders): ModuleList(\n",
            "    (0-7): 8 x DecoderBlock(\n",
            "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (mha): MultiHeadAttention(\n",
            "        (qkv_proj): Linear(in_features=128, out_features=384, bias=False)\n",
            "        (c_proj): Linear(in_features=128, out_features=128, bias=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (mlp): FeedForward(\n",
            "        (up_proj): Linear(in_features=128, out_features=512, bias=False)\n",
            "        (down_proj): Linear(in_features=512, out_features=128, bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (lnf): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (lm_head): Linear(in_features=128, out_features=10000, bias=False)\n",
            ")\n",
            "\n",
            "📊 Number of Parameters: 2.99M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ketNqGoLsK2U",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=cfg.optimizer.lr,\n",
        "    betas=cfg.optimizer.betas,\n",
        "    weight_decay=cfg.optimizer.weight_decay,\n",
        "    fused=cfg.optimizer.fused\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = LLMTrainer(model, optimizer, train_loader, valid_loader, tokenizer, config=cfg)"
      ],
      "metadata": {
        "id": "JMG2LHw6x4Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "4_N1nGVk7mtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcwx3XpZOXiw"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOVMvcCB7wjV"
      },
      "source": [
        "# 🔴 **Generate**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "def print_colored_wrapped(prompt, generated, width=100):\n",
        "    \"\"\"\n",
        "    Print prompt and generated text with color and line wrapping, preserving paragraph breaks (\\n\\n).\n",
        "    \"\"\"\n",
        "    full_text = prompt + generated\n",
        "    paragraphs = full_text.split('\\n\\n')  # Split by paragraph\n",
        "\n",
        "    first = True\n",
        "    for para in paragraphs:\n",
        "        # Apply line wrapping per paragraph\n",
        "        lines = textwrap.wrap(para, width=width)\n",
        "\n",
        "        for line in lines:\n",
        "            if first:\n",
        "                # Print prompt in green and the rest in cyan\n",
        "                prompt_part = line[:len(prompt)]\n",
        "                gen_part = line[len(prompt):]\n",
        "                print(colored(prompt_part, \"green\") + colored(gen_part, \"cyan\"))\n",
        "                prompt = ''  # only on first line\n",
        "                first = False\n",
        "            else:\n",
        "                print(colored(line, \"cyan\"))\n",
        "\n",
        "        print()  # extra newline between paragraphs\n"
      ],
      "metadata": {
        "id": "bQ_TnnfC-k00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    'In last night',\n",
        "    'Once upon',\n",
        "    'Once upon a time',\n",
        "    'One day, a little boy named TimTommy was a smart 3 year old, much smarter']"
      ],
      "metadata": {
        "id": "Nn-rU3iy9d9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for prompt in prompts:\n",
        "    # Generate n_rep samples\n",
        "    gen_text = generate(model, tokenizer, prompt, n_rep=3, max_seq_len=512, T=0.9, top_k=10)\n",
        "\n",
        "    # Print\n",
        "    print(100*\"=\")\n",
        "    for gtxt in gen_text:\n",
        "        prompt_len = len(prompt)\n",
        "        generated = gtxt[prompt_len:]\n",
        "        print_colored_wrapped(prompt, generated, width=100)\n",
        "        print(tokenizer.encode(gtxt))\n",
        "        print(100*\".\")\n"
      ],
      "metadata": {
        "id": "4OLk4HdN7zum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 2\n",
        "tokens = []\n",
        "for i, token in enumerate(ids[idx, 1:]):\n",
        "    if token.item() != 1:\n",
        "        tokens.append(token.item())\n",
        "    else:\n",
        "        break\n",
        "print(len(tokens), len(ids[idx]))\n",
        "\n",
        "pprint(tokenizer.decode(tokens))"
      ],
      "metadata": {
        "id": "hpFTH-lFeXLo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}