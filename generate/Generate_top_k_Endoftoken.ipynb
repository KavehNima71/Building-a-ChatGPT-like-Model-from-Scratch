{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOtMoHBg3TkLlk/+rYB1uze"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Generate** `top_k` `End_Of_token`"],"metadata":{"id":"yTFsqgldABNO"}},{"cell_type":"code","source":["def generate(model, tokenizer, prompt, n_rep=5, max_seq_len=128, T=0.9, top_k=10, device='cuda', seed=42):\n","  # Tokenize the prompt and convert it to a tensor on the specified device (e.g., GPU)\n","\n","    inputs = torch.tensor(tokenizer.encode(prompt).ids, dtype=torch.int, device=device)  # [T]\n","\n","    # Repeat the input prompt n_rep times to generate multiple sequences in parallel\n","    inputs = inputs.unsqueeze(0).repeat(n_rep, 1)  # Shape: [B, T] where B = n_rep\n","\n","    # Set the model to evaluation mode\n","    model.eval()\n","\n","    end_token_id = tokenizer.token_to_id('<|endoftext|>')\n","    finished = torch.zeros(n_rep, dtype=torch.bool, device=device)  # [B] where B = n_rep\n","\n","    # Initialize a random number generator for sampling\n","    sample_rng = torch.Generator(device=device)\n","    sample_rng.manual_seed(seed)\n","\n","    # Disable gradient calculation for faster inference\n","    with torch.no_grad():\n","      # Continue generating tokens until reaching the maximum sequence length\n","      while inputs.shape[-1] < max_seq_len and not finished.all():\n","        # Forward pass: get logits from the model\n","        logits = model(inputs)  # Shape: [B, T, vocab_size]\n","\n","        # Apply temperature scaling and softmax to get probabilities for the next token\n","        probs = torch.softmax(logits[:, -1, :] / T, dim=-1)   # Shape: [B, vocab_size]\n","\n","        # Select the top_k tokens with the highest probabilities\n","        topk_probs, topk_indices = torch.topk(probs, k=top_k, dim=-1)  # Shape: [B, top_k]\n","\n","        # Sample one token from the top_k candidates based on their probabilities\n","        ids = torch.multinomial(topk_probs, 1, generator=sample_rng)  # Shape: [B, 1]\n","\n","        # Map the sampled indices back to the original token IDs\n","        ids = torch.gather(topk_indices, -1, ids)  # Shape: [B, 1]\n","\n","        # Update finished flags\n","        finished |= (ids.squeeze(1) == end_token_id)\n","\n","        # For finished sequences, we append the end_token_id repeatedly to maintain shape\n","        ids[finished.unsqueeze(1)] = end_token_id\n","\n","        # Append the sampled tokens to the input sequence\n","        inputs = torch.cat((inputs, ids), dim=-1)  # Shape: [B, T+1]\n","\n","    # Cut off everything after the first occurrence of end_token_id\n","    final_outputs = []\n","    for sequence in inputs.tolist():\n","        if end_token_id in sequence[1:]:\n","          end_index = sequence[1:].index(end_token_id)\n","          final_outputs.append(sequence[:end_index+1])\n","        else:\n","            final_outputs.append(sequence)\n","\n","    # generated_text = tokenizer.decode_batch(inputs.tolist())\n","    generated_text = tokenizer.decode_batch(final_outputs)\n","    return generated_text"],"metadata":{"id":"9wREs4lGroOH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = 'in last'\n","generated_texts = generate(model, tokenizer, prompt, n_rep=3, max_seq_len=256, T=0.9, top_k=10, device='cuda', seed=43)\n","print('Generate top_k End_of_token:')\n","print()\n","for i, text in enumerate(generated_texts):\n","    display(HTML(f\"<span style='color: yellow;'>Generated {i+1}:</span> <span style='color: cyan;'>{prompt}</span><span style='color: White;'>{text[len(prompt):]}</span>\"))\n","    print('-'*150)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"executionInfo":{"status":"ok","timestamp":1748392462020,"user_tz":-210,"elapsed":1761,"user":{"displayName":"Donya bayadbedoneh","userId":"13676357871646449863"}},"outputId":"033a9084-b4df-451a-8a83-7b27f5ce69c1","id":"Iz-iAw-5UB-3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generate top_k End_of_token:\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span style='color: yellow;'>Generated 1:</span> <span style='color: cyan;'>in last</span><span style='color: White;'> night. He was so happy that he couldn't help but laugh. He was so glad that he had made a new friend. He went to bed that night with a smile on his face. He couldn't wait to get a new friend and play with him again!</span>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------------------------------------------------------------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span style='color: yellow;'>Generated 2:</span> <span style='color: cyan;'>in last</span><span style='color: White;'> week to the park. She wanted to find a new park. She saw a big tree with red flowers on it. She ran to the tree and picked up a flower. She saw Ben in a book. She wanted to read a book.\n","\n","She reached for one of Ben's books. She reached under the chair and saw a long piece of paper. She reached for it and tried to grab it. Ben pushed her. They both pulled and pulled. The paper flew off. It made a loud noise.\n","\n","\"Oh no!\" Ben said. He looked at the paper. He saw his tears. He felt sad. He felt angry. He was sad.\n","\n","\n","\n","\n","Mom. He looked at the broken the paper was sad. He was not know Lily had a big brother was angry. He did not had a bad thing of Anna's eyes and Ben was angry. He was gone. He had a crash. He broke his heart was not like a bumpy. He felt a red. He could not saw Anna had no one of the paper was not had no one of a bad. He was not have no one more. He was sad. He had no one of a bumpurelay. He was not had</span>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------------------------------------------------------------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span style='color: yellow;'>Generated 3:</span> <span style='color: cyan;'>in last</span><span style='color: White;'> night, there were two friends, a dog, and a rabbit. They loved to play together and have fun. One day, while they were playing together, they found a big piece of paper in the grass. \n","\n","The two friends had never found a piece of paper. They decided to make a sign with the paper. They drew a post in the box and made a sign that said \"Dogive\". \n","\n","The dog and star were very surprised. It had never seen a sign before. It wanted to find out its name on the paper, but it couldn't find it. \n","\n","Just then, the man gave up and the mailman arrived to their goodbyes. \"Where is now!\"\n","\n","\n","The mailman had to the boy had an old woman said, the little bear said, who had no one of the postcipalcuffen and said \"you. It was a voice gave up of its little brow. It was a voice of the other one of the other person with a boy, \"cuffing the man in its name was holding a bright that was about the box was sent the other person in the mailman, said, said it said, it was holding a man with lots of course came and the</span>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------------------------------------------------------------------------------------\n"]}]}]}